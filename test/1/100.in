Expert C Programming: Deep C Secrets
By Peter van der Linden
Introduction
C code. C code run. Run code run…please!
—Barbara Ling
All C programs do the same thing: look at a character and do nothing with it.
—Peter Weinberger
Have you ever noticed that there are plenty of C books with suggestive names like C Traps and Pitfalls, or The C Puzzle Book, or Obfuscated C and Other Mysteries, but other programming languages don't have books like that? There's a very good reason for this!
C programming is a craft that takes years to perfect. A reasonably sharp person can learn the basics of C quite quickly. But it takes much longer to master the nuances of the language and to write enough programs, and enough different programs, to become an expert. In natural language terms, this is the difference between being able to order a cup of coffee in Paris, and (on the Metro) being able to tell a native Parisienne where to get off. This book is an advanced text on the ANSI C programming language. It is intended for people who are already writing C programs, and who want to quickly pick up some of the insights and techniques of experts.
Expert programmers build up a tool kit of techniques over the years; a grab-bag of idioms, code fragments, and deft skills. These are acquired slowly over time, learned from looking over the shoulders of more experienced colleagues, either directly or while maintaining code written by others. Other lessons in C are self-taught. Almost every beginning C programmer independently rediscovers the mistake of writing:
if (i=3)
instead of:
if (i==3)
Once experienced, this painful error (doing an assignment where comparison was intended) is rarely
repeated. Some programmers have developed the habit of writing the literal first, like this: if (3==i). Then, if an equal sign is accidentally left out, the compiler will complain about an
"attempted assignment to literal." This won't protect you when comparing two variables, but every little bit helps.

The $20 Million Bug
In Spring 1993, in the Operating System development group at SunSoft, we had a "priority one" bug report come in describing a problem in the asynchronous I/O library. The bug was holding up the sale of $20 million worth of hardware to a customer who specifically needed the library functionality, so we were extremely motivated to find it. After some intensive debugging sessions, the problem was finally traced to a statement that read :
x==2;
It was a typo for what was intended to be an assignment statement. The programmer 's finger had bounced on the "equals" key, accidentally pressing it twice instead of once. The statement as written compared x to 2, generated true or false, and discarded the result .
C is enough of an expression language that the compiler did not complain about a statement which evaluated an expression, had no side-effects, and simply threw away the result. We didn't know whether to bless our good fortune at locating the problem, or cry with frustration at such a common typing error causing such an expensive problem. Some versions of the lint program would have detected this problem, but it's all too easy to avoid the automatic use of this essential tool.
This book gathers together many other salutary stories. It records the wisdom of many experienced programmers, to save the reader from having to rediscover everything independently. It acts as a guide for territory that, while broadly familiar, still has some unexplored corners. There are extended discussions of major topics like declarations and arrays/pointers, along with a great many hints and mnemonics. The terminology of ANSI C is used throughout, along with translations into ordinary English where needed.
Programming Challenge
OR
Handy Heuristic

Sample Box
Along the way, we have Programming Challenges outlined in boxes like this one.
These are suggestions for programs that you should write.
There are also Handy Heuristics in boxes of their own.
These are ideas, rules-of-thumb, or guidelines that work in practice. You can adopt them as your own. Or you can ignore them if you already have your own guidelines that you like better.
Convention
One convention that we have is to use the names of fruits and vegetables for variables (only in small code fragments, not in any real program, of course):
char pear[40]; double peach; int mango = 13; long melon = 2001;
This makes it easy to tell what's a C reserved word, and what's a name the programmer supplied. Some people say that you can't compare apples and oranges, but why not—they are both hand-held round edible things that grow on trees. Once you get used to it, the fruit loops really seem to help. There is one other convention—sometimes we repeat a key point to emphasize it. In addition, we sometimes repeat a key point to emphasize it.
Like a gourmet recipe book, Expert C Programming has a collection of tasty morsels ready for the reader to sample. Each chapter is divided into related but self-contained sections; it's equally easy to read the book serially from start to finish, or to dip into it at random and review an individual topic at length. The technical details are sprinkled with many true stories of how C programming works in practice. Humor is an important technique for mastering new material, so each chapter ends with a "light relief" section containing an amusing C story or piece of software folklore to give the reader a change of pace.
Readers can use this book as a source of ideas, as a collection of C tips and idioms, or simply to learn more about ANSI C, from an experienced compiler writer. In sum, this book has a collection of useful ideas to help you master the fine art of ANSI C. It gathers all the information, hints, and guidelines together in one place and presents them for your enjoyment. So grab the back of an envelope, pull out your lucky coding pencil, settle back at a comfy terminal, and let the fun begin!
Some Light Relief—Tuning File Systems
Some aspects of C and UNIX are occasionally quite lighthearted. There's nothing wrong with wellplaced whimsy. The IBM/Motorola/Apple PowerPC architecture has an E.I.E.I.O. instruction [1] that stands for "Enforce In-order Execution of I/O". In a similar spirit, there is a UNIX command,

tunefs, that sophisticated system administrators use to change the dynamic parameters of a
filesystem and improve the block layout on disk.
[1] Probably designed by some old farmer named McDonald.
The on-line manual pages of the original tunefs, like all Berkeley commands, ended with a "Bugs"
section. In this case, it read:
Bugs: This program should work on mounted and active file systems, but it doesn't. Because the superblock is not kept in the buffer cache, the program will only take effect if it is run on dismounted file systems; if run on the root file system, the system must be rebooted. You can tune a file system, but you can't tune a fish.
Even better, the word-processor source had a comment in it, threatening anyone who removed that last phrase! It said:
Take this out and a UNIX Demon will dog your steps from now until the time_t's wrap around.
When Sun, along with the rest of the world, changed to SVr4 UNIX, we lost this gem. The SVr4 manpages don't have a "Bugs" section—they renamed it "Notes" (does that fool anyone?). The "tuna fish" phrase disappeared, and the guilty party is probably being dogged by a UNIX demon to this day. Preferably lpd.
Programming Challenge
Computer Dating
When will the time_t's wrap around?
Write a program to find out.
1. Look at the definition of time_t. This is in file /usr/include/time.h. 2. Code a program to place the highest value into a variable of type time_t, then
pass it to ctime() to convert it into an ASCII string. Print the string. Note that ctime has nothing to do with the language C, it just means "convert time."

For how many years into the future does the anonymous technical writer who removed the comment have to worry about being dogged by a UNIX daemon? Amend your program to find out.
1. Obtain the current time by calling time(). 2. Call difftime() to obtain the number of seconds between now and the highest
value of time_t.
3. Format that value into years, months, weeks, days, hours, and minutes. Print it.
Is it longer than your expected lifetime?
Programming Solution
Computer Dating
The results of this exercise will vary between PCs and UNIX systems, and will depend on the way time_t is stored. On Sun systems, this is just a typedef for long. Our first attempted solution is
#include <stdio.h> #include <time.h> int main() {
time_t biggest = 0x7FFFFFFF; printf("biggest = %s \n", ctime(&biggest) ); return 0; }
This gives a result of:
biggest = Mon Jan 18 19:14:07 2038
However, this is not the correct answer! The function ctime() converts its argument into
local time, which will vary from Coordinated Universal Time (also known as Greenwich Mean Time), depending on where you are on the globe. California, where this book was written, is eight hours behind London, and several years ahead.
We should really use the gmtime() function to obtain the largest UTC time value. This function doesn't return a printable string, so we call asctime()to get this. Putting it all

together, our revised program is
#include <stdio.h> #include <time.h>
int main() { time_t biggest = 0x7FFFFFFF;
printf("biggest = %s \n", asctime(gmtime(&biggest)) ); return 0; }
This gives a result of:
biggest = Tue Jan 19 03:14:07 2038
There! Squeezed another eight hours out of it!
But we're still not done. If you use the locale for New Zealand, you can get 13 more hours, assuming they use daylight savings time in the year 2038. They are on DST in January because they are in the southern hemisphere. New Zealand, because of its easternmost position with respect to time zones, holds the unhappy distinction of being the first country to encounter bugs triggered by particular dates.
Even simple-looking things can sometimes have a surprising twist in software. And anyone who thinks programming dates is easy to get right the first time probably hasn't done much of it.
Chapter 1. C Through the Mists of Time
C is quirky, flawed, and an enormous success.
—Dennis Ritchie
the prehistory of C…the golden rule for compiler-writers… early experiences with C…the standard I/O library and C preprocessor…K&R C…the present day: ANSI C…it's nice, but is it standard?…the structure of the ANSI C standard…reading the ANSI C standard for fun, pleasure, and profit…how quiet is a "quiet change"?…some light relief—the implementation-defined effects of pragmas
The Prehistory of C
The story of C begins, paradoxically, with a failure. In 1969 the great Multics project—a joint venture between General Electric, MIT, and Bell Laboratories to build an operating system—was clearly in trouble. It was not only failing to deliver the promised fast and convenient on-line system, it was failing to deliver anything usable at all. Though the development team eventually got Multics creaking into action, they had fallen into the same tarpit that caught IBM with OS/360. They were trying to create an operating system that was much too big and to do it on hardware that was much too small.

Multics is a treasure house of solved engineering problems, but it also paved the way for C to show that small is beautiful. As the disenchanted Bell Labs staff withdrew from the Multics project, they looked around for other tasks. One researcher, Ken Thompson, was keen to work on another operating system, and made several proposals (all declined) to Bell management. While waiting on official approval, Thompson and co-worker Dennis Ritchie amused themselves porting Thompson's "Space Travel" software to a little-used PDP-7. Space Travel simulated the major bodies of the solar system, and displayed them on a graphics screen along with a space craft that could be piloted and landed on the various planets. At the same time, Thompson worked intensively on providing the PDP-7 with the rudiments of a new operating system, much simpler and lighter-weight than Multics. Everything was written in assembler language. Brian Kernighan coined the name "UNIX" in 1970, paro-dying the lessons now learned from Multics on what not to do. Figure 1-1 charts early C, UNIX, and associated hardware.
Figure 1-1. Early C, UNIX, and Associated Hardware
In this potential chicken-and-egg situation, UNIX definitely came well before C (and it's also why UNIX system time is measured in seconds since January 1, 1970—that's when time began). However, this is the story not of poultry, but of programming. Writing in assembler proved awkward; it took longer to code data structures, and it was harder to debug and understand. Thompson wanted the advantages of a high-level implementation language, but without the PL/I [1] performance and complexity problems that he had seen on Multics. After a brief and unsuccessful flirtation with Fortran, Thompson created the language B by simplifying the research language BCPL [2] so its interpreter would fit in the PDP-7's 8K word memory. B was never really successful; the hardware memory limits only provided room for an interpreter, not a compiler. The resulting slow performance prevented B from being used for systems programming of UNIX itself.
[1] The difficulties involved in learning, using, and implementing PL/I led one programmer to pen this verse: IBM had a PL/I / Its syntax worse than JOSS / And everywhere this language went / It was a total loss. JOSS was an earlier language, also not noted for simplicity. [2] "BCPL: A Tool for Compiler Writing and System Programming," Martin Richards, Proc. AFIPS Spring Joint Computer Conference, 34 (1969), pp. 557-566. BCPL is not an acronym for the "Before C Programming

Language", though the name is a happy coincidence. It is the "Basic Combined Programming Lan-guage"— "basic" in the sense of "no frills"—and it was developed by a combined effort of researchers at London University and Cambridge University in England. A BCPL implementation was available on Multics.
Software Dogma
The Golden Rule of Compiler-Writers:
Performance Is (almost) Everything.
Performance is almost everything in a compiler. There are other concerns: meaningful error messages, good documentation, and product support. These factors pale in comparison with the importance users place on raw speed. Compiler performance has two aspects: runtime performance (how fast the code runs) and compile time performance (how long it takes to generate code). Runtime performance usually dominates, except in development and student environments.
Many compiler optimizations cause longer compilation times but make run times much shorter. Other optimizations (such as dead code elimination, or omitting runtime checks) speed up both compile time and run time, as well as reducing memory use. The downside of aggressive optimization is the risk that invalid results may not be flagged. Optimizers are very careful only to do safe transformations, but programmers can trigger bad results by writing invalid code (e.g., referencing outside an array's bounds because they "know" that the desired variable is adjacent).
This is why performance is almost but not quite everything—if you don't get accurate results, then it's immaterial how fast you get them. Compiler-writers usually provide compiler options so each programmer can choose the desired optimizations. B's lack of success, until Dennis Ritchie created a high-performance compiled version called "New B," illustrates the golden rule for compiler-writers.
B simplified BCPL by omitting some features (such as nested procedures and some loop-ing constructs) and carried forward the idea that array references should "decompose" into pointer-plusoffset references. B also retained the typelessness of BCPL; the only operand was a machine word.
Thompson conceived the ++ and -- operators and added them to the B compiler on the PDP-7. The
popular and captivating belief that they're in C because the PDP-11 featured corresponding autoincrement/decrement addressing modes is wrong! Auto increment and decrement predate the PDP-11 hardware, though it is true that the C statement to copy a character in a string:
*p++ = *s++;
can be compiled particularly efficiently into the PDP-11 code:

movb (r0)+,(r1)+
leading some people to wrongly conclude that the former was created especially for the latter.
A typeless language proved to be unworkable when development switched in 1970 to the newly introduced PDP-11. This processor featured hardware support for datatypes of several different sizes, and the B language had no way to express this. Performance was also a problem, leading Thompson to reimplement the OS in PDP-11 assembler rather than B. Dennis Ritchie capitalized on the more powerful PDP-11 to create "New B," which solved both problems, multiple datatypes, and performance. "New B"—the name quickly evolved to "C"—was compiled rather than interpreted, and it introduced a type system, with each variable described in advance of use.
Early Experiences with C
The type system was added primarily to help the compiler-writer distinguish floats, doubles, and characters from words on the new PDP-11 hardware. This contrasts with languages like Pascal, where the purpose of the type system is to protect the programmer by restricting the valid operations on a data item. With its different philosophy, C rejects strong typing and permits the programmer to make assignments between objects of different types if desired. The type system was almost an afterthought, never rigorously evaluated or extensively tested for usability. To this day, many C programmers believe that "strong typing" just means pounding extra hard on the keyboard.
Many other features, besides the type system, were put in C for the C compiler-writer's benefit (and why not, since C compiler-writers were the chief customers for the first few years). Features of C that seem to have evolved with the compiler-writer in mind are:
• Arrays start at 0 rather than 1. Most people start counting at 1, rather than zero. Compilerwriters start with zero because we're used to thinking in terms of offsets. This is sometimes
tough on non-compiler-writers; although a[100] appears in the definition of an array, you'd better not store any data at a[100], since a[0] to a[99] is the extent of the array.
• The fundamental C types map directly onto underlying hardware. There is no built-in complex-number type, as in Fortran, for example. The compiler-writer does not have to invest any effort in supporting semantics that are not directly provided by the hardware. C didn't support floating-point numbers until the underlying hardware provided it.
• The auto keyword is apparently useless. It is only meaningful to a compiler-writer
making an entry in a symbol table—it says this storage is automatically allocated on entering the block (as opposed to global static allocation, or dynamic allocation on the heap). Auto is irrelevant to other programmers, since you get it by default. • Array names in expressions "decay" into pointers. It simplifies things to treat arrays as pointers. We don't need a complicated mechanism to treat them as a composite object, or suffer the inefficiency of copying everything when passing them to a function. But don't make the mistake of thinking arrays and pointers are always equivalent; more about this in Chapter 4. • Floating-point expressions were expanded to double-length-precision everywhere. Although this is no longer true in ANSI C, originally real number constants were always doubles, and float variables were always converted to double in all expressions. The reason, though we've never seen it appear in print, had to do with PDP-11 floating-point hardware. First, conversion from float to double on a PDP-11 or a VAX is really cheap: just append an extra word of zeros. To convert back, just ignore the second word. Then understand that some PDP-11 floating-point hardware had a mode bit, so it would do either all single-precision or all double-precision arithmetic, but to switch between the two you had to change modes.

Since most early UNIX programs weren't floating-point-intensive, it was easier to put the box in double-precision mode and leave it there than for the compiler-writer to try to keep track of it!
• No nested functions (functions contained inside other functions). This simplifies the compiler and slightly speeds up the runtime organization of C programs. The exact mechanism is described in Chapter 6, "Poetry in Motion: Runtime Data Structures."
• The register keyword. This keyword gave the compiler-writer a clue about what
variables the programmer thought were "hot" (frequently referenced), and hence could usefully be kept in registers. It turns out to be a mistake. You get better code if the compiler does the work of allocating registers for individual uses of a variable, rather than reserving
them for its entire lifetime at declaration. Having a register keyword simplifies the
compiler by transferring this burden to the programmer.
There were plenty of other C features invented for the convenience of the C compiler-writer, too. Of itself this is not necessarily a bad thing; it greatly simplified the language, and by shunning complicated semantics (e.g., generics or tasking in Ada; string handling in PL/I; templates or multiple inheritance in C++) it made C much easier to learn and to implement, and gave faster performance.
Unlike most other programming languages, C had a lengthy evolution and grew through many intermediate shapes before reaching its present form. It has evolved through years of practical use into a language that is tried and tested. The first C compiler appeared circa 1972, over 20 years ago now. As the underlying UNIX system grew in popularity, so C was carried with it. Its emphasis on lowlevel operations that were directly supported by the hardware brought speed and portability, in turn helping to spread UNIX in a benign cycle.
The Standard I/O Library and C Preprocessor
The functionality left out of the C compiler had to show up somewhere; in C's case it appears at runtime, either in application code or in the runtime library. In many other languages, the compiler plants code to call runtime support implicitly, so the programmer does not need to worry about it, but almost all the routines in the C library must be explicitly called. In C (when needed) the programmer must, for example, manage dynamic memory use, program variable-size arrays, test array bounds, and carry out range checks for him or herself.
Similarly, I/O was originally not defined within C; instead it was provided by library routines, which in practice have become a standardized facility. The portable I/O library was written by Mike Lesk [3] and first appeared around 1972 on all three existing hardware platforms. Practical experience showed that performance wasn't up to expectations, so the library was tuned and slimmed down to become the standard I/O library.
[3] It was Michael who later expressed the hilariously ironic rule of thumb that "designing the system so that the manual will be as short as possible minimizes learning effort." (Datamation, November 1981, p.146). Several comments come to mind, of which "Bwaa ha ha!" is probably the one that minimizes learning effort.
The C preprocessor, also added about this time at the suggestion of Alan Snyder, fulfilled three main purposes:
• String replacement, of the form "change all foo to baz", often to provide a symbolic name for a constant.

• Source file inclusion (as pioneered in BCPL). Common declarations could be separated out into a header file, and made available to a range of source files. Though the ".h" convention was adopted for the extension of header files, unhappily no convention arose for relating the header file to the object library that contained the corresponding code.
• Expansion of general code templates. Unlike a function, the same macro argument can take different types on successive calls (macro actual arguments are just slotted unchanged into the output). This feature was added later than the first two, and sits a little awkwardly on C. White space makes a big difference to this kind of macro expansion.
#define a(y) a_expanded(y) a(x);
expands into:
a_expanded(x);
However,
#define a (y) a_expanded (y) a(x); is transformed into:
(y) a_expanded (y)(x);
Not even close to being the same thing. The macro processor could conceivably use curly braces like the rest of C to indicate tokens grouped in a block, but it does not.
There's no extensive discussion of the C preprocessor here; this reflects the view that the only appropriate use of the preprocessor is for macros that don't require extensive discussion. C++ takes this a step further, introducing several conventions designed to make the preprocessor completely unnecessary.
Software Dogma
C Is Not Algol
Writing the UNIX Version 7 shell (command interpreter) at Bell Labs in the late 1970's, Steve Bourne decided to use the C preprocessor to make C a little more like Algol-68. Earlier at Cambridge University in England, Steve had written an Algol-68 compiler, and
found it easier to debug code that had explicit "end statement" cues, such as if ... fi or case ... esac. Steve thought it wasn't easy enough to tell by looking at a " }"

what it matches. Accordingly, he set up many preprocessor definitions:
#define STRING char * #define IF if( #define THEN ){ #define ELSE } else { #define FI ;} #define WHILE while ( #define DO ){ #define OD ;} #define INT int #define BEGIN { #define END }
This enabled him to code the shell using code like this:
INT compare(s1, s2) STRING s1; STRING s2;
BEGIN WHILE *s1++ == *s2 DO IF *s2++ == 0 THEN return(0); FI OD return(*--s1 - *s2);
END
Now let's look at that again, in C this time:
int compare(s1, s2) char * s1, *s2;
{ while (*s1++ == *s2) { if (*s2++ == 0) return (0); } return (*--s1 - *s2);
}
This Algol-68 dialect achieved legendary status as the Bourne shell permeated far beyond Bell Labs, and it vexed some C programmers. They complained that the dialect made it much harder for other people to maintain the code. The BSD 4.3 Bourne shell (kept in /bin/sh) is written in the Algol subset to this day!
I've got a special reason to grouse about the Bourne shell—it's my desk that the bugs reported against it land on! Then I assign them to Sam! And we do see our share of bugs:

the shell doesn't use malloc, but rather does its own heap storage management using sbrk. Maintenance on software like this too often introduces a new bug for every two it solves. Steve explained that the custom memory allocator was done for efficiency in stringhandling, and that he never expected anyone except himself to see the code. The Bournegol C dialect actually inspired The International Obfuscated C Code Competition, a whimsical contest in which programmers try to outdo each other in inventing mysterious and confusing programs (more about this competition later). Macro use is best confined to naming literal constants, and providing shorthand for a few well-chosen constructs. Define the macro name all in capitals so that, in use, it's instantly clear it's not a function call. Shun any use of the C preprocessor that modifies the underlying language so that it's no longer C.
K&R C
By the mid 1970's the language was recognizably the C we know and love today. Further refinements took place, mostly tidying up details (like allowing functions to return structure values) or extending
the basic types to match new hardware (like adding the keywords unsigned and long). In 1978
Steve Johnson wrote pcc, the portable C compiler. The source was made available outside Bell Labs, and it was very widely ported, forming a common basis for an entire generation of C compilers. The evolutionary path up to the present day is shown in Figure 1-2.
Figure 1-2. Later C
Software Dogma
An Unusual Bug One feature C inherited from Algol-68 was the assignment operator. This allows a repeated operand to be written once only instead of twice, giving a clue to the code generator that
operand addressing can be similarly thrifty. An example of this is writing b+=3 as an abbreviation for b=b+3. Assignment operators were originally written with assignment first, not the operator, like this: b=+3. A quirk in B's lexical analyzer made it simpler to

implement as =op rather than op= as it is today. This form was confusing, as it was too easy
to mix up
b=-3; /* subtract 3 from b */ and
b= -3; /* assign -3 to b */
The feature was therefore changed to its present ordering. As part of the change, the code
formatter indent was modified to recognize the obsolete form of assignment operator
and swap it round to operator assignment. This was very bad judgement indeed; no formatter should ever change anything except the white space in a program. Unhappily, two things happened. The programmer introduced a bug, in that almost anything (that wasn't a variable) that appeared after an assignment was swapped in position.
If you were "lucky" it would be something that would cause a syntax error, like
epsilon=.0001; being swapped into
epsilon.=0001;
But a source statement like
valve=!open; /* valve is set to logical negation of open */ would be silently transmogrified into
valve!=open; /* valve is compared for inequality to open */ which compiled fine, but did not change the value of valve.
The second thing that happened was that the bug lurked undetected. It was easy to work around by inserting a space after the assignment, so as the obsolete form of assignment operator declined in use, people just forgot that indent had been kludged up to "improve" it. The indent bug persisted in some implementations up until the mid-1980's. Highly pernicious!
In 1978 the classic C bible, The C Programming Language, was published. By popular accla-mation, honoring authors Brian Kernighan and Dennis Ritchie, the name "K&R C" was applied to this version of the language. The publisher estimated that about a thousand copies would be sold; to date (1994) the figure is over one and a half million (see Figure 1-3). C is one of the most successful programming languages of the last two decades, perhaps the most successful. But as the language spread, the temptation to diverge into dialects grew.
Figure 1-3. Like Elvis, C is Everywhere

The Present Day: ANSI C
By the early 1980's, C had become widely used throughout the industry, but with many different implementations and changes. The discovery by PC implementors of C's advantages over BASIC provided a fresh boost. Microsoft had an implementation for the IBM PC which introduced new
keywords (far, near, etc.) to help pointers to cope with the irregular architecture of the Intel 80x86
chip. As many other non-pcc-based implementations arose, C threatened to go the way of BASIC and evolve into an ever-diverging family of loosely related languages.
It was clear that a formal language standard was needed. Fortunately, there was much precedent in this area—all successful programming languages are eventually standardized. However, the problem with standards manuals is that they only make sense if you already know what they mean. If people write them in English, the more precise they try to be, the longer, duller and more obscure they become. If they write them using mathematical notation to define the language, the manuals become inaccessible to too many people.
Over the years, the manuals that define programming language standards have become longer, but no easier to understand. The Algol-60 Reference Definition was only 18 pages long for a language of comparable complexity to C; Pascal was described in 35 pages. Kernighan and Ritchie took 40 pages for their original report on C; while this left several holes, it was adequate for many implementors. ANSI C is defined in a fat manual over 200 pages long. This book is, in part, a description of practical use that lightens and expands on the occasionally opaque text in the ANSI Standard document.
In 1983 a C working group formed under the auspices of the American National Standards Institute. Most of the process revolved around identifying common features, but there were also changes and
significant new features introduced. The far and near keywords were argued over at great length,
but ultimately did not make it into the mildly UNIX-centric ANSI standard. Even though there are more than 50 million PC's out there, and it is by far the most widely used platform for C implementors, it was (rightly in our view) felt undesirable to mutate the language to cope with the limitations of one specific architecture.
Handy Heuristic

Which Version of C to Use?
At this point, anyone learning or using C should be working with ANSI C, not K&R C.
The language standard draft was finally adopted by ANSI in December 1989. The international standards organization ISO then adopted the ANSI C standard (unhappily removing the very useful "Rationale" section and making trivial—but very annoy-ing—formatting and paragraph numbering changes). ISO, as an international body, is technically the senior organization, so early in 1990 ANSI readopted ISO C (again exclud-ing the Rationale) back in place of its own version. In principle, therefore, we should say that the C standard adopted by ANSI is ISO C, and we should refer to the language as ISO C. The Rationale is a useful text that greatly helps in understanding the standard, and it's published as a separate document. [4]
[4] The ANSI C Rationale (only) is available for free by anonymous ftp from the site ftp.uu.net, in directory /doc/standards/ansi/X3.159-1989/.
(If you're not familiar with anonymous ftp, run, don't walk, to your nearest bookstore and buy a book on Internet, before you become <insert lame driving metaphor of choice> on the Information Highway.) The Rationale has also been published as a book, ANSI C Rationale, New Jersey, Silicon Press, 1990. The ANSI C standard itself is not available by ftp anywhere because ANSI derives an important part of its revenue from the sale of printed standards.
Handy Heuristic
Where to Get a Copy of the C Standard
The official name of the standard for C is: ISO/IEC 9899-1990. ISO/IEC is the International Organization for Standardization International Electrotechnical Commission. The standards bodies sell it for around $130.00. In the U.S. you can get a copy of the standard by writing to:
American National Standards Institute 11 West 42nd Street New York, NY 10036 Tel. (212) 642-4900

Outside the U.S. you can get a copy by writing to:
ISO Sales Case postale 56 CH-1211 Genève 20 Switzerland
Be sure to specify the English language edition.
Another source is to purchase the book The Annotated ANSI C Standard by Herbert Schildt, (New York, Osborne McGraw-Hill, 1993). This contains a photographically reduced, but complete, copy of the standard. Two other advantages of the Schildt book are that at $39.95 it is less than one-third the price charged by the standards bodies, and it is available from your local bookstore which, unlike ANSI or ISO, has probably heard of the twentieth century, and will take phone orders using credit cards.
In practice, the term "ANSI C" was widely used even before there was an ISO Working Group 14 dedicated to C. It is also appropriate, because the ISO working group left the technical development of the initial standard in the hands of ANSI committee X3J11. Toward the end, ISO WG14 and X3J11 collaborated to resolve technical issues and to ensure that the resulting standard was acceptable to both groups. In fact, there was a year's delay at the end, caused by amending the draft standard to cover international issues such as wide characters and locales.
It remains ANSI C to anyone who has been following it for a few years. Having arrived at this good thing, everyone wanted to endorse the C standard. ANSI C is also a European standard (CEN 29899) and an X/Open standard. ANSI C was adopted as a Federal Information Processing Standard, FIPS 160, issued by the National Institute of Standards and Technology in March 1991, and updated on August 24, 1992. Work on C continues—there is talk of adding a complex number type to C.
It's Nice, but Is It Standard?
Save a tree—disband an ISO working group today.
—Anonymous
The ANSI C standard is unique in several interesting ways. It defines the following terms, describing characteristics of an implementation. A knowledge of these terms will aid in understanding what is and isn't acceptable in the language. The first two are concerned with unportable code; the next two deal with bad code; and the last two are about portable code.
Unportable Code:
implementation-defined— The compiler-writer chooses what happens, and has to document it.
Example: whether the sign bit is propagated, when shifting an int right.
unspecified— The behavior for something correct, on which the standard does not impose any requirements.
Example: the order of argument evaluation.

Bad Code:
undefined— The behavior for something incorrect, on which the standard does not impose any requirements. Anything is allowed to happen, from nothing, to a warning message to program termination, to CPU meltdown, to launching nuclear missiles (assuming you have the correct hardware option installed).
Example: what happens when a signed integer overflows.
a constraint— This is a restriction or requirement that must be obeyed. If you don't, your program behavior becomes undefined in the sense above. Now here's an amazing thing: it's easy to tell if something is a constraint or not, because each topic in the standard has a subparagraph labelled "Constraints" that lists them all. Now here's an even more amazing thing: the standard specifies [5] that compilers only have to produce error messages for violations of syntax and constraints! This means that any semantic rule that's not in a constraints subsection can be broken, and since the behavior is undefined, the compiler is free to do anything and doesn't even have to warn you about it!
[5] In paragraph 5.1.1.3, "Diagnostics", if you must know. Being a language standard, it doesn't say something simple like you've got to flag at least one error in an incorrect program. It says something grander that looks like it was drawn up by a team of corporate lawyers being paid by the word, namely, a conforming implementation shall [*] produce at least one diagnostic message (identified in an implementation-dependent manner) for every translation unit that contains a violation of any syntax rule or constraint. Diagnostic messages need not be produced in other circumstances.
[*] Useful rule from Brian Scearce [ ] —if you hear a programmer say "shall" he or she is quoting from a standard.
[ ] Inventor of the nested footnote.
Example: the operands of the % operator must have integral type. So using a non-integral type with %
must cause a diagnostic.
Example of a rule that is not a constraint: all identifiers declared in the C standard header files are
reserved for the implementation, so you may not declare a function called malloc() because a
standard header file already has a function of that name. But since this is not a constraint, the rule can be broken, and the compiler doesn't have to warn you! More about this in the section on "interpositioning" in Chapter 5.
Software Dogma
Undefined Behavior Causes CPU Meltdown in IBM PC's!
The suggestion of undefined software behavior causing CPU meltdown isn't as farfetched as it first appears.

The original IBM PC monitor operated at a horizontal scan rate provided by the video controller chip. The flyback transformer (the gadget that produces the high voltage needed to accelerate the electrons to light up the phosphors on the monitor) relied on this being a reasonable frequency. However, it was possible, in software, to set the video chip scan rate to zero, thus feeding a constant voltage into the primary side of the transformer. It then acted as a resistor, and dissipated its power as heat rather than transforming it up onto the screen. This burned the monitor out in seconds. Voilà: undefined software behavior causes system meltdown!
Portable Code:
strictly-conforming— A strictly-conforming program is one that:
• only uses specified features. • doesn't exceed any implementation-defined limit. • has no output that depends on implementation-defined, unspecified, or undefined features.
This was intended to describe maximally portable programs, which will always produce the identical output whatever they are run on. In fact, it is not a very interesting class because it is so small compared to the universe of conforming programs. For example, the following program is not strictly conforming:
#include <limits.h> #include <stdio.h> int main() { (void) printf("biggest int is %d", INT_MAX); return 0;}
/* not strictly conforming: implementation-defined output! */
For the rest of this book, we usually don't try to make the example programs be strictly conforming. It clutters up the text, and makes it harder to see the specific point under discussion. Program portability is valuable, so you should always put the necessary casts, return values, and so on in your real-world code.
conforming— A conforming program can depend on the nonportable features of an implementation. So a program is conforming with respect to a specific implementation, and the same program may be nonconforming using a different compiler. It can have extensions, but not extensions that alter the behavior of a strictly-conforming program. This rule is not a constraint, however, so don't expect the compiler to warn you about violations that render your program nonconforming!
The program example above is conforming.
Translation Limits
The ANSI C standard actually specifies lower limits on the sizes of programs that must successfully translate. These are specified in paragraph 5.2.4.1. Most languages say how many characters can be in a dataname, and some languages stipulate what limit is acceptable for the maximum number of array dimensions. But specifying lower bounds on the sizes of various other features is unusual, not to say

unique in a programming language standard. Members of the standardization committee have commented that it was meant to guide the choice of minimum acceptable sizes.
Every ANSI C compiler is required to support at least:
• 31 parameters in a function definition • 31 arguments in a function call • 509 characters in a source line • 32 levels of nested parentheses in an expression
• The maximum value of long int can't be any less than 2,147,483,647, (i.e., long integers
are at least 32 bits).
and so on. Furthermore, a conforming compiler must compile and execute a program in which all of the limits are tested at once. A surprising thing is that these "required" limits are not actually constraints—so a compiler can choke on them without issuing an error message.
Compiler limits are usually a "quality of implementation" issue; their inclusion in ANSI C is an implicit acknowledgment that it will be easier to port code if definite expectations for some capacities are set for all implementations. Of course, a really good implementation won't have any preset limits, just those imposed by external factors like available memory or disk. This can be done by using linked lists, or dynamically expanding the size of tables when necessary (a technique explained in Chapter 10).
The Structure of the ANSI C Standard
It's instructive to make a quick diversion into the provenance and content of the ANSI C standard. The ANSI C standard has four main sections:
Section 4: An introduction and definition of terminology (5 pages).
Section 5: Environment (13 pages). This covers the system that surrounds and supports C, including what happens on program start-up, on termination, and with signals and floating-point operations. Translator lower limits and character set information are also given.
Section 6: The C language (78 pages) This part of the standard is based on Dennis Ritchie's classic "The C Reference Manual" which appeared in several publications, including Appendix A of The C Programming Language. If you compare the Standard and the Appendix, you can see most headings are the same, and in the same order. The topics in the standard have a more rigid format, however, that looks like Figure 1-4 (empty subparagraphs are simply omitted).
Figure 1-4. How a Paragraph in the ANSI C Standard Looks

The original Appendix is only 40 pages, while this section of the standard is twice as long.
Section 7: The C runtime library (81 pages). This is a list of the library calls that a conforming implementation must provide—the standard services and routines to carry out essential or helpful functions. The ANSI C standard's section 7 on the C runtime library is based on the /usr/group 1984 standard, with the UNIX-specific parts removed. "/usr/group" started life as an international user group for UNIX. In 1989 it was renamed "UniForum", and is now a nonprofit trade association dedicated to the promotion of the UNIX operating system.
UniForum's success in defining UNIX from a behavioral perspective encouraged many related initiatives, including the X/Open portability guides (version 4, XPG/4 came out in October 1992), IEEE POSIX 1003, the System V Interface Definition, and the ANSI C libraries. Everyone coordinated with the ANSI C working group to ensure that all their draft standards were mutually consistent. Thank heaven.
The ANSI C standard also features some useful appendices:
Appendix F: Common warning messages. Some popular situations for which diagnostic messages are not required, but when it is usually helpful to generate them nonetheless.
Appendix G: Portability issues. Some general advice on portability, collected into one place from throughout the standard. It includes information on behavior that is unspecified, undefined, and implementation-defined.

Software Dogma
Standards Are Set in Concrete, Even the Mistakes Just because it's written down in an international standard doesn't mean that it's complete, consistent, or even correct. The IEEE POSIX 1003.1-1988 standard (it's an OS standard that defines UNIX-like behavior) has this fun contradiction: "[A pathname] ... consists of at most PATH_MAX bytes, including the terminating null character."—section 2.3 "PATH_MAX is the maximum number of bytes in a pathname (not a string length; count excludes a terminating null)."—section 2.9.5 So PATH_MAX bytes both includes and does not include the terminating null! An interpretation was requested, and the answer came back (IEEE Std 1003.1-1988/INT, 1992 Edition, Interpretation number: 15, p. 36) that it was an inconsistency and both can be right (which is pretty strange, since the whole point is that both can't be right). The problem arose because a change at the draft stage wasn't propagated to all occurrences of the wording. The standards process is formal and rigid, so it cannot be fixed until an update is approved by a balloting group. This kind of error also appears in the C standard in the very first footnote, which refers to the accompanying Rationale document. In fact, the Rationale no longer accompanies the C Standard—it was deleted when ownership of the standard moved to ISO.
Handy Heuristic
Differences between K&R C and ANSI C Rest assured that if you know K&R C, then you already know 90% of ANSI C. The differences between ANSI C and K&R C fall into four broad categories, listed below in order of importance:
1. The first category contains things that are new, very different, and important. The only feature in this class is the prototype—writing the parameter types as part of

the function declaration. Prototypes make it easy for a compiler to check function use with definition. 2. The second category is new keywords. Several keywords were officially added:
enum for enumerated types (first seen in late versions of pcc), const, volatile, signed, void, along with their associated semantics. The neverused entry keyword that found its way into C, apparently by oversight, has been
retired. 3. The third category is that of "quiet changes"—some feature that still compiles, but
now has a slightly different meaning. There are many of these, but they are mostly not very important, and can be ignored until you push the boundaries and actually stumble across one of them. For example, now that the preprocessing rules are more tightly defined, there's a new rule that adjacent string literals are concatenated. 4. The final category is everything else, including things that were argued over interminably while the language was being standardized, but that you will almost certainly never encounter in practice, for example, token-pasting or trigraphs. (Trigraphs are a way to use three characters to express a single character that a particularly inadequate computer might not have in its character set. Just as the
digraph \t represents "tab", so the trigraph ??< represents "open curly brace".)
The most important new feature was "prototypes", adopted from C++. Prototypes are an extension of function declarations so that not just the name and return type are known, but also all the parameter types, allowing the compiler to check for consistency between parameter use and declaration. "Prototype" is not a very descriptive term for "a function name with all its arguments"; it would have been more meaningful to call it a "function signature", or a "function specification" as Ada does.
Software Dogma
The Protocol of Prototypes
The purpose of prototypes is to include some information on parameter types (rather than merely giving the function name and return value type) when we make a forward declaration of a function. The compiler can thus check the types of arguments in a function call against the way the parameters were defined. In K&R C, this check was deferred till link time or, more usually, omitted entirely. Instead of
char * strcpy(); declarations in header files now look like this:
char * strcpy(char *dst, const char *src);
You can also omit the names of the parameters, leaving only the types:

char * strcpy(char * , const char * );
Don't omit the parameter names. Although the compiler doesn't check these, they often convey extra semantic information to the programmer. Similarly, the definition of the function has changed from

char * strcpy(dst, src) char *dst, *src;
{ ... } to
char * strcpy(char *dst, const char *src) /* note no semi-colon! */ { ... }
Instead of being ended with a semicolon, the function header is now directly followed by a single compound statement comprising the body of the function.
Prototype everything new you write and ensure the prototype is in scope for every call. Don't go back to prototype your old K&R code, unless you take into account the default type promotions—more about this in Chapter 8.
Having all these different terms for the same thing can be a little mystifying. It's rather like the way drugs have at least three names: the chemical name, the manufacturer 's brand name, and the street name.
Reading the ANSI C Standard for Fun, Pleasure, and Profit
Sometimes it takes considerable concentration to read the ANSI C Standard and obtain an answer from it. A sales engineer sent the following piece of code into the compiler group at Sun as a test case.

1 foo(const char 2 3 main(int argc, 4{ 5 foo(argv); 6}

**p) char

{ } **argv)

If you try compiling it, you'll notice that the compiler issues a warning message, saying:

line 5: warning: argument is incompatible with prototype
The submitter of the code wanted to know why the warning message was generated, and what part of the ANSI C Standard mandated this. After all, he reasoned,

argument char *s matches parameter const char *p
This is seen throughout all library string functions.
So doesn't argument char **argv match parameter const char **p ?
The answer is no, it does not. It took a little while to answer this question, and it's educational in more than one sense, to see the process of obtaining the answer. The analysis was carried out by one of Sun's "language lawyers," [6] and it runs like this:
[6] The New Hacker's Dictionary defines a language lawyer as "a person who will show you the five sentences scattered through a 200-plus-page manual that together imply the answer to your question 'if only you had thought to look there.'" Yep! That's exactly what happened in this case.
The Constraints portion of Section 6.3.2.2 of the ANSI C Standard includes the phrase:
Each argument shall have a type such that its value may be assigned to an object with the unqualified version of the type of its corresponding parameter.
This says that argument passing is supposed to behave like assignment.
Thus, a diagnostic message must be produced unless an object of type const char ** may be assigned a value of type char **.To find out whether this assignment is legal, flip to the section
on simple assignment, Section 6.3.16.1, which includes the following constraint:
One of the following shall hold:…
• Both operands are pointers to qualified or unqualified versions of compatible types, and the type pointed to by the left has all the qualifiers of the type pointed to by the right.
It is this condition that makes a call with a char * argument corresponding to a const char *
parameter legal (as seen throughout the string routines in the C library). This is legal because in the code
char * cp; const char *ccp; ccp = cp;
• The left operand is a pointer to "char qualified by const". • The right operand is a pointer to "char" unqualified.
• The type char is a compatible type with char, and the type pointed to by the left operand
has all the qualifiers of the type pointed to by the right operand (none), plus one of its own (const).
Note that the assignment cannot be made the other way around. Try it if you don't believe me.
cp = ccp; /* results in a compilation warning */

Does Section 6.3.16.1 also make a call with a char ** argument corresponding to a const char ** parameter legal? It does not.
The Examples portion of Section 6.1.2.5 states:
The type designated "const float *" is not a qualified type—its type is "pointer to const-qualified float" and is a pointer to a qualified type.
Analogously, const char ** denotes a pointer to an unqualified type. Its type is a pointer to a
pointer to a qualified type.
Since the types char ** and const char ** are both pointers to unqualified types that are not the same type, they are not compatible types. Therefore, a call with an argument of type char ** corresponding to a parameter of type const char ** is not allowed. Therefore, the
constraint given in Section 6.3.2.2 is violated, and a diagnostic message must be produced.
This is a subtle point to grasp. Another way of looking at it is to note that:
• the left operand has type FOO2—a pointer to FOO, where FOO is an unqualified pointer to a character qualified by the const qualifier, and
• the right operand has type BAZ2—a pointer to BAZ, where BAZ is an unqualified pointer to a character with no qualifiers.
FOO and BAZ are compatible types, but FOO2 and BAZ2 differ other than in qualifica-tion of the thing immediately pointed to and are therefore not compatible types; therefore the left and right operands are unqualified pointers to types that are not compatible. Compatibility of pointer types is not transitive. Therefore, the assignment or function call is not permitted. However, note that the restriction serves mainly to annoy and confuse users. The assignment is currently allowed in C++ translators based on cfront (though that might change).
Handy Heuristic
Const Isn't
The keyword const doesn't turn a variable into a constant! A symbol with the const
qualifier merely means that the symbol cannot be used for assignment. This makes the value re ad -onl y through that symbol; it does not prevent the value from being modified through some other means internal (or even external) to the program. It is pretty much useful only for qualifying a pointer parameter, to indicate that this function will not change the data that argument points to, but other functions may. This is perhaps the most common use of
const in C and C++.

A const can be used for data, like so:
const int limit = 10;
and it acts somewhat as in other languages. When you add pointers into the equation, things get a little rough:
const int * limitp = &limit; int i=27; limitp = &i;
This says that limitp is a pointer to a constant integer. The pointer cannot be used to
change the integer; however, the pointer itself can be given a different value at any time. It will then point to a different location and dereferencing it will yield a different value!
The combination of const and * is usually only used to simulate call-by-value for array
parameters. It says, "I am giving you a pointer to this thing, but you may not change it."
This idiom is similar to the most frequent use of void *. Although that could
theoretically be used in any number of circumstances, it's usually restricted to converting pointers from one type to another.
Analogously, you can take the address of a constant variable, and, well, perhaps I had better
not put ideas into people's heads. As Ken Thompson pointed out, "The const keyword
only confuses library interfaces with the hope of catching some rare errors." In retrospect,
the const keyword would have been better named readonly.
True, this whole area in the standard appears to have been rendered into English from Urdu via Danish by translators who had only a passing familiarity with any of these tongues, but the standards committee was having such a good time that it seemed a pity to ruin their fun by asking for some simpler, clearer rules.
We felt that a lot of people would have questions in the future, and not all of them would want to follow the process of reasoning shown above. So we changed the Sun ANSI C compiler to print out more information about what it found incompatible. The full message now says:
Line 6: warning: argument #1 is incompatible with prototype: prototype: pointer to pointer to const char : "barf.c", line
1 argument : pointer to pointer to char
Even if a programmer doesn't understand why, he or she will now know what is incompatible.
How Quiet is a "Quiet Change"?
Not all the changes in the standard stick out as much as prototypes. ANSI C made a number of other changes, usually aimed at making the language more reliable. For instance, the "usual arithmetic

conversions" changed between ye olde originale K&R C and ANSI C. Thus, where Kernighan and Ritchie say something like:
Section 6.6 Arithmetic Conversions
A great many operators cause conversions and yield result types in a similar way. This pattern will be called the "usual arithmetic conversions."
First, any operands of type char or short are converted to int, and any of type float are converted to double. Then if either operand is double, the other is converted to double and that is the type of the result. Otherwise, if either operand is long, the other is converted to long and that is the type of the result. Otherwise, if either operand is unsigned, the other is converted to unsigned and that is the type of the result. Otherwise, both operands must be int, and that is the type of the result.
The ANSI C manual has closed the loopholes by rewriting this as:
Section 6.2.1.1 Characters and Integers (the integral promotions)
A char, a short int, or an int bit-field, or their signed or unsigned varieties, or an enumeration type, may be used in an expression wherever an int or unsigned int may be used. If an int can represent all the values of the original type, the value is converted to an int; otherwise it is converted to an unsigned int. These are called the integral promotions.
Section 6.2.1.5 Usual Arithmetic Conversions
Many binary operators that expect operands of arithmetic type cause conversions and yield result types in a similar way. The purpose is to yield a common type, which is also the type of the result. This pattern is called the "usual arithmetic conversions."
First, if either operand has type long double, the other operand is converted to long double. Otherwise, if either operand has type double, the other operand is converted to double. Otherwise, if either operand has type float, the other operand is converted to float. Otherwise the integral promotions [refer to section 6.2.1.1 for the integral promotions] are performed on both operands. Then the following rules are applied.
If either operand has type unsigned long int, the other operand is converted to unsigned long int. Otherwise, if one operand has type long int and the other has type unsigned int, if a long int can represent all values of an unsigned int the operand of type unsigned int is converted to long int; if a long int cannot represent all the values of an unsigned int, both operands are converted to unsigned long int. Otherwise, if either operand has type long int, the other operand is converted to long int. Otherwise, if either operand has type unsigned int, the other operand is converted to unsigned int. Otherwise, both operands have type int.
The values of floating operands and of the results of floating expressions may be represented in greater precision and range than that required by the type; the types are not changed thereby.
In English (complete with loopholes and lack of precision), the ANSI C version would mean something like:
Operands with different types get converted when you do arithmetic. Everything is converted to the type of the floatiest, longest operand, signed if possible without losing bits.

The unsigned preserving approach (K&R C) says that when an unsigned type mixes with an int or smaller signed type, the result is an unsigned type. This is a simple rule, independent of hardware, but, as in the example below, it does sometimes force a negative result to lose its sign!
The value preserving approach (ANSI C) says that when you mix integral operand types like this, the result type is signed or unsigned depending on the relative sizes of the operand types.
The following program fragment will print a different message under ANSI and pre-ANSI compilers:
main() { if ( -1 < (unsigned char) 1 ) printf("-1 is less than (unsigned char) 1: ANSI
semantics "); else printf("-1 NOT less than (unsigned char) 1: K&R
semantics "); }
Depending on whether you compile it under K&R or ANSI C, the expression will be evaluated differently. The same bitpatterns are compared, but interpreted as either a negative number, or as an unsigned and hence positive number.
Software Dogma
A Subtle Bug
Even though the rules were changed, subtle bugs can and do still occur. In this example, the variable d is one less than the index needed, so the code copes with it. But the if statement did not evaluate to true. Why, and what, is the bug?
int array[] = { 23, 34, 12, 17, 204, 99, 16 }; #define TOTAL_ELEMENTS (sizeof(array) / sizeof(array[0]))
main() {
int d= -1, x; /* ... */
if (d <= TOTAL_ELEMENTS-2) x = array[d+1];
/* ... */

} The defined variable TOTAL_ELEMENTS has type unsigned int (because the return type
of sizeof is "unsigned"). The test is comparing a signed int with an unsigned int quantity. So d is promoted to unsigned int. Interpreting -1 as an unsigned int yields a big positive number, making the clause false. This bug occurs under ANSI C, and under K&R C if
sizeof() had an unsigned return type in a given implementation. It can be fixed by putting an int cast immediately before the TOTAL_ELEMENTS:
if (d <= (int) TOTAL_ELEMENTS - 2)
Handy Heuristic
Advice on Unsigned Types Avoid unnecessary complexity by minimizing your use of unsigned types. Specifically, don't use an unsigned type to represent a quantity just because it will never be negative (e.g., "age" or "national_debt").
Use a signed type like int and you won't have to worry about boundary cases in the
detailed rules for promoting mixed types. Only use unsigned types for bitfields or binary masks. Use casts in expressions, to make all the operands signed or unsigned, so the compiler does not have to choose the result type.
If this sounds a little tricky or surprising, it is! Work through the example using the rules on the previous page. Finally, just so that we don't see this code appear as a bad example in a future edition of The Elements of Programming Style [7], we'd better explain that we used
[7] The Elements of Programming Style, Kernighan (yes, that Kernighan) and Plauger, New York, McGrawHill, 1978. A thundering good read, credible plot, great little book—buy it, read it, live it!
#define TOTAL_ELEMENTS (sizeof(array) / sizeof(array[0]))
instead of
#define TOTAL_ELEMENTS (sizeof(array) / sizeof(int))

because the former allows the base type of the array to change (from, say, int to char) without needing a change to the #define, too.
The Sun ANSI C compiler team felt that moving from "unsigned preserving" to "value preserving" was a totally unnecessary change to C's semantics that would surprise and dismay anyone who encountered it unexpectedly. So, under the "principle of least astonishment," the Sun compiler recognizes and compiles ANSI C features, unless the feature would give a different result under K&R C. If this is the case, the compiler issues a warning and uses the K&R interpretation by default. In situations like the one above, the programmer should use a cast to tell the compiler what the final desired type is. Strict ANSI semantics are available on a Sun workstation running Solaris 2.x by using
the compiler option -Xc.
There are plenty of other updates to K&R C in ANSI C, including a few more so-called "quiet changes" where code compiles under both but has a different meaning. Based on the usual programmer reaction when they are discovered, these really should be called "very noisy changes indeed". In general, the ANSI committee tried to change the language as little as possible, consistent with revising some of the things that undeniably needed improvement.
But that's enough background on the ANSI C family tree. After a little light relief in the following section, proceed to the next chapter and get started on code!
Some Light Relief—The Implementation-Defined Effects of Pragmas . . .
The Free Software Foundation is a unique organization founded by ace MIT hacker Richard Stallman. By the way, we use "hacker" in the old benevolent sense of "gifted programmer;" the term has been debased by the media, so outsiders use it to mean "evil genius." Like the adjective bad, "hacker" now has two opposing meanings, and you have to figure it out from the context.
Stallman's Free Software Foundation was founded on the philosophy that software should be free and freely available to all. FSF's charter is "to eliminate restrictions on copying, redistribution, understanding and modification of computer programs" and their ambition is to create a publicdomain implementation of UNIX called GNU (it stands for "GNU's Not UNIX." Yes, really.)
Many computer science graduate students and others agree with the GNU philosophy, and have worked on software products that FSF packages and distributes for free. This pool of skilled labor donating their talent has resulted in some good software. One of FSF's best products is the GNU C compiler family. gcc is a robust, aggressive optimizing compiler, available for many hardware platforms and sometimes better than the manufacturer's compiler. Using gcc would not be appropriate for all projects; there are questions of maintenance and future product continuity. There are other tools needed besides a compiler, and the GNU debugger was unable to operate on shared libraries for a long time. GNU C has also occasionally been a little, shall we say, giddy in development.
When the ANSI C standard was under development, the pragma directive was introduced. Borrowed from Ada, #pragma is used to convey hints to the compiler, such as the desire to expand a particular function in-line or suppress range checks. Not previously seen in C, pragma met with
some initial resistance from a gcc implementor, who took the "implementation-defined" effect very literally—in gcc version 1.34, the use of pragma causes the compiler to stop compiling and launch a computer game instead! The gcc manual contained the following:

The "#pragma" command is specified in the ANSI standard to have an arbitrary implementationdefined effect. In the GNU C preprocessor, "#pragma" first attempts to run the game "rogue"; if that fails, it tries to run the game "hack"; if that fails, it tries to run GNU Emacs displaying the Tower of Hanoi; if that fails, it reports a fatal error. In any case, preprocessing does not continue.
—Manual for version 1.34 of the GNU C compiler
And the corresponding source code in the preprocessor part of the compiler was:
/* * the behavior of the #pragma directive is implementation
defined. * this implementation defines it as follows. */
do_pragma () {
close (0); if (open ("/dev/tty", O_RDONLY, 0666) != 0)
goto nope; close (1); if (open ("/dev/tty", O_WRONLY, 0666) != 1)
goto nope; execl ("/usr/games/hack", "#pragma", 0); execl ("/usr/games/rogue", "#pragma", 0); execl ("/usr/new/emacs", "-f", "hanoi", "9", "-kill", 0); execl ("/usr/local/emacs", "-f", "hanoi", "9", "-kill", 0); nope: fatal ("You are in a maze of twisty compiler features, all different"); }
Especially droll is the fact that the description in the user manual is wrong, in that the code shows that "hack" is tried before "rogue".
Chapter 2. It's Not a Bug, It's a Language Feature
Bugs are by far the largest and most successful class of entity, with nearly a million known species. In this respect they outnumber all the other known creatures about four to one.
—Professor Snopes' Encyclopedia of Animal Life
why language features matter…sins of commission: switches let you down with fall through…available hardware is a crayon?…too much default visibility…sins of mission: overloading the camel's back…"some of the operators have the wrong precedence"…the early bug gets() the Internet worm…sins of omission: mail won't go to users with an "f" in their user name…space–the final frontier…the compiler date is corrupted…lint should never have been separated out…some light relief—some features really are bugs

Why Language Features Matter—The Way the Fortran Bug Really Happened!
The details of a programming language really matter. They matter because the details make the difference between a reliable language and an error-prone one. This was dramatically revealed in Summer 1961 by a programmer at NASA, testing a Fortran subroutine used to calculate orbital trajectories. [1] The subroutine had already been used for several brief Mercury flights, but it was mysteriously not providing the precision that was expected and needed for the forthcoming orbital and lunar missions. The results were close, but not quite as accurate as expected.
[1] The story is very widely misreported, and inaccurate versions appear in many programming language texts. Indeed, it has become a classic urban legend among programmers. The definitive account, from Fred Webb who worked at NASA at the time and saw the actual source code, can be seen in "Fortran Story—The Real Scoop" in Forum on Risks to the Public in Computers and Related Systems, vol. 9, no. 54, ACM Committee on Computers and Public Policy, December 12, 1989.
After checking the algorithm, the data, and the expected results at great length, the engineer finally noticed this statement in the code:
DO 10 I=1.10
Clearly, the programmer had intended to write a DO loop of the form:
DO 10 I=1,10
In Fortran, blank characters are not significant and can even occur in the middle of an identifier. The designers of Fortran intended this to help cardpunch walloppers and to aid the readability of programs,
so you could have identifiers like MAX Y. Unfortunately, the compiler quite correctly read the statement as DO10I = 1.10
Variables do not have to be declared in Fortran. The statement as written caused the value 1.1 to be
assigned to the implicitly declared floating point variable DO10I. The statements in the body of the
intended loop were executed once instead of ten times, and a first approximation of a calculation took place instead of an iterative convergence. After cor-recting the period to a comma, the results were correct to the expected accuracy.
The bug was detected in time and never caused a Mercury space flight to fail as many versions claim (a different bug, in the Mariner flights, described at the end of the chapter, did have this effect), but it does graphically illustrate the importance of language design. C has all-too-many similar ambiguities or near-ambiguities. This chapter describes a representative sample of the most common ones, and how they typically show up as bugs. There are other problems that can arise in C; for example, any
time you encounter the string malloc(strlen(str)); it is almost always sure to be an error, where malloc(strlen(str)+1); was meant. This is because almost all the other string-
handling routines include the room needed for the trailing nul terminator, so people get used to not
making the special provision for it that strlen needs. The malloc example is an error in the
programmer 's knowledge of a library routine, whereas this chapter concentrates on problematic areas in C itself, rather than the programmer 's use of it.

One way of analyzing the deficiencies in a programming language is to consider the flaws in three possible categories: things the language does that it shouldn't do; things it doesn't do that it should; and things that are completely off the wall. For convenience, we can call these "sins of commission," "sins of omission," and "sins of mission," respectively. The following sections describe C features in these categories.
This chapter isn't meant as fatal criticism of C. C is a wonderful programming language with many strengths. Its popularity as the implementation language of choice on many platforms is well-deserved. But, as my grandmother used to say, you can't run a super-conducting supercollider without smashing a few atoms, and you can't analyze C without looking at the flaws as well as the high points. Reviewing areas for improvement is one of the factors that gradually improves the science of software engineering and the art of programming language design. That's why C++ is so disappointing: it does nothing to address some of the most fundamental problems in C, and its most important addition (classes) builds on the deficient C type model. So with the spirit of enquiry dedicated to improving future languages, here are some observations and case histories.
Handy Heuristic
The One 'l' nul and the Two 'l' null
Memorize this little rhyme to recall the correct terminology for pointers and ASCII zero:
The one "l" NUL ends an ASCII string,
The two "l" NULL points to no thing.
Apologies to Ogden Nash, but the three "l" nulll means check your spelling. The ASCII character with the bit pattern of zero is termed a "NUL". The special pointer value that means the pointer points nowhere is "NULL". The two terms are not interchangeable in meaning.
Sins of Commission
The "sins of commission" category covers things that the language does, that it shouldn't do. This includes error-prone features like the switch statement, automatic concatenation of adjacent string literals, and default global scope.
Switches Let You Down with Fall Through
The general form of a switch statement is:

switch (expression){ case constant-expression: default: case constant-expression: }

zero-or-more-statements zero-or-more-statements zero-or-more-statements

Each case is introduced by triplets of the keyword case, followed by an integer-valued constant or
constant expression, followed by a colon. Execution starts at the case that matches the expression. The default case (if present) can appear anywhere in the list of cases, and will be executed if none of the cases match. If there's no default case and none of the cases match, nothing is done by this statement. Some people have suggested that it might be better to have a runtime error for the "no match" case, as does Pascal. Runtime error checking is almost unknown in C—checking for dereferencing an invalid pointer is about the only case, and even that limited case can't be fully done under MS-DOS.

Handy Heuristic

Runtime Checking in MS-DOS
Invalid pointers can be the bane of a programmer's life. It's just too easy to reference memory using an invalid pointer. All virtual memory architectures will fault a process that dereferences a pointer outside its address space as soon as this happens. But MS-DOS doesn't support virtual memory, so it cannot catch the general case at the instant of failure.
However, MS-DOS can and does use a heuristic to check the specific case of dereferencing a null pointer, after your program has finished. Both Microsoft and Borland C, before entering your program, save the contents of location zero. As part of their exit code, they check whether it now contains a different value. If it does, it's a pretty fair bet that your program stored through a null pointer, and the runtime system prints the warning "null pointer assignment".
More about this in Chapter 7.
Runtime checking goes against the C philosophy that the programmer knows what he or she is doing and is always right.
The cases and the default can come in any order, though by convention the default case is usually the last one. A conformant C compiler must permit at least 257 case labels for a switch statement (ANSI C Standard, section 5.2.4.1). This is to allow a switch on an 8-bit character (256 possible values, plus EOF).
Switch has several problems, one of which is that it is too relaxed about what it accepts in the cases. For example, you can declare some local storage by following the switch's opening curly brace with a declaration. This is an artifact of the original compiler—most of the same code that processed any

compound statement could be reused to process the braces-enclosed part of a switch. So a declaration is naturally accepted, though it's futile to add an initial value as part of a declaration in a switch statement, as it will not be exe-cuted—execution starts at the case that matches the expression.
Handy Heuristic
Need Some Temporary Store? Be the First on Your Block! It is always the case in C that where you have some statements opening a block
{ statements
you can always add some declarations in between, like this:
{ declarations statements
You might use this if allocating memory was expensive, and hence avoided if possible. A compiler is free to ignore it, though, and allocate the space for all local blocks on calling a function. Another use is to declare some variables whose use is really localized to this block.
if ( a>b ) /* swap a, b */
{ int tmp = a; a = b; b = tmp;
}
C++ takes this a step further still, and allows arbitrary intermingling of statements and declarations, and even embedding declarations in the middle of "for" statements.
for (int i=0; i<100; i++){...
If not used with restraint, that can quickly lead to confusion.

Another problem is that any statements inside a switch can be labelled and jumped to, allowing control to be passed around arbitrarily:

switch (i) { case 5+3: do_again: case 2: printf("I loop default : i++; case 3: ;
}

unremittingly

\n");

goto

do_again;

The fact that all the cases are optional, and any form of statement, including labelled statements, is permitted, means that some errors can't be detected even by lint. A colleague of mine once mistyped
defau1t for the default label (i.e., mistyped a digit "1" for the letter "l"). It was very hard to track
this bug down, and it effectively removed the default case from the switch statement. However, it still compiled without errors, and even a detailed review of the source showed nothing untoward. Most lints don't catch this one.

By the way, since the keyword const doesn't really mean constant in C,

const int two=2;
switch (i) { case 1: printf("case 1 \n"); case two: printf("case 2 \n");
**error** ^^^ integral constant expression expected
case 3: printf("case 3 \n"); default: ; }
the code above will produce a compilation error like the one shown. This isn't really the fault of the switch statement, but switch statements are one place the problem of constants not being constant shows up.
Perhaps the biggest defect in the switch statement is that cases don't break automatically after the actions for a case label. Once a case statement is executed, the flow of control continues down, executing all the following cases until a break statement is reached. The code

switch (2) { case 1: printf("case 1 \n"); case 2: printf("case 2 \n"); case 3: printf("case 3 \n"); case 4: printf("case 4 \n"); default: printf("default \n");
}
will print out

case 2 case 3 case 4 default
This is known as "fall through" and was intended to allow common end processing to be done, after some case-specific preparation had occurred. In practice it's a severe misfea-ture, as almost all case
actions end with a break;. Most versions of lint even issue a warning if they see one case falling
through into another.
Software Dogma
Default Fall Through Is Wrong 97% of the Time
We analyzed the Sun C compiler sources to see how often the default fall through was used. The Sun ANSI C compiler front end has 244 switch statements, each of which has an average of seven cases. Fall through occurs in just 3% of all these cases.
In other words, the normal switch behavior is wrong 97% of the time. It's not just in a compiler—on the contrary, where fall through was used in this analysis it was often for situations that occur more frequently in a compiler than in other software, for instance, when compiling operators that can have either one or two operands:
switch( operator->num_of_operands ) { case 2: process_operand( operator->operand_2 ); /* FALLTHRU */ case 1: process_operand( operator->operand_1 ); break;
}
Case fall through is so widely recognized as a defect that there's even a special comment convention, shown above, that tells lint "this really is one of the 3% of cases where fall through was desired." The inconvenience of default fall through is borne out in many other programs.
We conclude that default fall through on switches is a design defect in C. The overwhelm-ing majority of the time you don't want to do it and have to write extra code to defeat it. As the Red Queen said to Alice in Through the Looking Glass, you can't deny that even if you used both hands.
Another Switch Problem—What Does break

Break?
This is a replica of the code that caused a major disruption of AT&T phone service throughout the U.S. AT&T's network was in large part unusable for about nine hours starting on the afternoon of January 15, 1990. Telephone exchanges (or "switching systems" in phone jargon) are all computer systems these days, and this code was running on a model 4ESS Central Office Switching System. It demonstrates that it is too easy in C to overlook exactly which control constructs are affected by a "break" statement.
network code() {
switch (line) {
case THING1: doit1(); break;
case THING2: if (x == STUFF) { do_first_stuff();
if (y == OTHER_STUFF) break; do_later_stuff();
} /* coder meant to break to here... */ initialize_modes_pointer(); break;
default: processing();
} /* ...but actually broke to here! */
use_modes_pointer();/* leaving the modes_pointer uninitialized */
}
This is a simplified version of the code, but the bug was real enough. The programmer wanted to break out of the "if" statement, forgetting that "break" actually gets you out of the nearest enclosing iteration or switch statement. Here, it broke out of the switch, and
executed the call to use_modes_pointer() —but the necessary initialization had
not been done, causing a failure further on.
This code eventually caused the first major network problem in AT&T's 114-year history. The saga is described in greater detail on page 11 of the January 22, 1990 issue of Telephony magazine. The supposedly fail-safe design of the network signaling system actually spread the fault in a chain reaction, bringing down the entire long distance network.
And it all rested on a C switch statement.

Available Hardware Is a Crayon?
One new feature introduced with ANSI C is the convention that adjacent string literals are concatenated into one string. This replaces the old way of constructing multiline messages using escaped newlines, and starting each continuation string in column one.
Old style:

printf( "A favorite children's book \ is 'Muffy Gets It: the hilarious tale of a cat, \ a boy, and his machine gun'" );
This can now be written as a series of adjacent string literals that will automatically be joined together as one at compile-time. The nul character that normally ends a string literal is dropped from all joined string literals except the last one.
New style:

printf( "A second favorite children's book " "is 'Thomas the tank engine and the Naughty Enginedriver
who " "tied down Thomas's boiler safety valve'" );
However, the automatic concatenation means that a missing comma in an initialization list of string literals no longer causes a diagnostic message. A missing comma now results in a silent marriage of adjacent strings. This has dire consequences in circumstances like the following:

char *available_resources[] = { "color monitor", "big disk",

"Cray" /*

whoa! no comma! */

"on-line drawing routines",

"mouse", "keyboard", "power cables", };

/* and what's this extra comma? */

So available_resources[2] is "Crayon-line drawing routines". There's quite a difference between having a "Cray" with "on-line drawing routines" and just having some routines to draw lines with crayons...

The total number of resources is one less than expected, so writing to
available_resources[6] will trash another variable. And by the way, that trailing comma
after the final initializer is not a typo, but a blip in the syntax carried over from aboriginal C. Its presence or absence is allowed but has no significance. The justification claimed in the ANSI C

rationale is that it makes automated generation of C easier. The claim would be more credible if trailing commas were permitted in every comma-sepa-rated list, such as in enum declarations, or multiple variable declarators in a single declaration. They are not.
Handy Heuristic
First Time Through
This hint shows a simple way to get a different action the first time through a section of code.
The function below will do a different action on its first invocation than on all subsequent calls. There are other ways of achieving this; this way minimizes the switches and conditional testing.
generate_initializer(char * string) {
static char separator=''; printf( "%c %s \n", separator, string); separator = ','; }
The first time through, this will print a space followed by an initializer. All subsequent initializers (if any) will be preceded by a comma. Viewing the specification as "first time through, prefix with a space" rather than "last time through, omit the comma suffix" makes this simple to program.
The claim is hard to believe, as an automated program can output a comma or no comma by having a statically declared character initialized to space and then set to comma. This will exhibit the correct behavior and is trivial to code. There are other examples of comma-separated items in C, where a comma may not terminate the list. The unnecessary, but allowed, comma after the last initializer serves mostly to muddy the waters of an already murky syntax.
Too Much Default Visibility
Whenever you define a C function, its name is globally visible by default. You can prefix the function
name with the redundant extern keyword or leave it off, and the effect is the same. The function is
visible to anything that links with that object file. If you want to restrict access to the function, you are
obliged to specify the static keyword.

function apple (){ /* visible everywhere */ } extern function pear () { /* visible everywhere */ }
static function turnip(){ /* not visible outside this file */ }
In practice, almost everyone tends to define functions without adding extra storage-class specifiers, so global scope prevails.
With the benefit of practical experience, default global visibility has been conclusively and repeatedly demonstrated to be a mistake. Software objects should have the most limited scope by default. Programmers should explicitly take action when they intend to give something global scope.
The problem of too much scope interacts with another common C convention, that of interpositioning. Interpositioning is the practice of supplanting a library function by a user-written function of the same name. Many C programmers are completely unaware of this feature, so it is described in the chapter on linking. For now, just make the mental note: "interpositioning—I should learn more about that."
The problem of too wide scope is often seen in libraries: one library needs to make an object visible to another library. The only possibility is to make it globally known; but then it is visible to anyone that links with the library. This is an "all-or-nothing" visibil-ity—symbols are either globally known or not known at all. There's no way to be more selective in revealing information in C.
The problem is made worse by the fact that you can't nest function definitions inside other functions, as you can in Pascal. So a collection of "internal" functions for one big function have to be outside it. Nobody remembers to make them static, so they're globally visible by default. The Ada and Modula-2 languages both address this problem in a man-ageable way by having program units specify exactly what symbols they are exporting and what they are importing.
Sins of Mission
The "sins of mission" category covers things in C that just seem misdirected, or a bad fit to the language. This includes features like the brevity of C (caused in part by excessive reuse of symbols) and problems with operator precedence.
Overloading the Camel's Back
One problem is that C is so terse. Just adding, changing, or omitting a single character often gives you a program that is still valid but does something entirely different. Worse than that, many symbols are "overloaded"—given different meanings when used in different contexts. Even some keywords are overloaded with several meanings, which is the main reason that C scope rules are not intuitively clear to programmers. Table 2-1 shows how similar C symbols have multiple different meanings.

Symbol
static

Table 2-1. Symbol Overloading in C Meaning
Inside a function, retains its value between calls

At the function level, visible only in this file [1]

extern Applied to a function definition, has global scope (and is redundant)

void

Applied to a variable, defined elsewhere As the return type of a function, doesn't return a value

In a pointer declaration, the type of a generic pointer

In a parameter list, takes no parameters

*

The multiplication operator

Applied to a pointer, indirection

In a declaration, a pointer

&

Bitwise AND operator

Address-of operator

=

Assignment operator

==

Comparison operator

<=

Less-than-or-equal-to operator

<<=

Compound shift-left assignment operator

<

Less-than operator

<

Left delimiter in #include directive

()

Enclose formal parameters in a function definition

Make a function call

Provide expression precedence

Convert (cast) a value to a different type

Define a macro with arguments

Make a macro call with arguments

Enclose the operand of the sizeof operator when it is a typename

[1] You're probably wondering what possible reason there could be for re-using the static keyword with
these wildly different meanings. If you find out, please let us know, too.

There are other symbols that are also confusingly similar. One flustered programmer once puzzled
over the statement if (x>>4) and asked, "What does it mean? Is it saying 'If x is much greater
than 4?'"

The kind of place where overloading can be a problem is in statements like:

p = N * sizeof * q;
Quickly now, are there two multiplications or only one? Here's a hint: the next statement is:
r = malloc( p );
The answer is that there's only one multiplication, because sizeof is an operator that here takes as its
operand the thing pointed to by q (i.e., *q). It returns the size in bytes of the type of thing to which q
points, convenient for the malloc function to allocate more memory. When sizeof 's operand is a type it has to be enclosed in parentheses, which makes people wrongly believe it is a function call, but for a variable this is not required.
Here's a more complicated example:
apple = sizeof (int) * p;
What does this mean? Is it the size of an int, multiplied by p? Or the size of whatever p points at, but cast to an int? Or something even weirder? The answer isn't given here, because part of being an expert programmer is learning to write little test programs to probe questions like this. Try it and see!
The more work you make one symbol do, the harder it is for the compiler to detect anomalies in your use of it. It's not just the kind of people who sing along with the Tiki birds at Disneyland who have trouble here. C does seem to be a little further out on the ragged edge of token ambiguity than most other languages.
"Some of the Operators Have the Wrong Precedence"
You know that you've definitely found a problem when the authors of the original report on C tell you that "some of the operators have the wrong precedence", as Kernighan and Ritchie mention on page 3 of The C Programming Language. Despite this admission, there were no changes in the precedence of operators for ANSI C. It's not surprising; any change in precedence would have imposed an intolerable burden on the existing source base.
But which C operators specifically have the wrong precedence? The answer is "any that appear misleading when you apply them in the regular way." Some operators whose precedence has often caused trouble for the unwary are shown in Figure 2-1.
Figure 2-1. Precedence Problems of C Operators

Most of these become more understandable if you sit down to consider them at length. The case involving the comma occasionally causes conniption fits in programmers, though. For example, when this line is executed:
i=1,2;
what value does i end up with? Well, we know that the value of a comma operator is the value of the rightmost operand. But here, assignment has higher precedence, so you actually get:
(i=1), 2; /* i gets the value 1 */
i gets the value 1; then the literal 2 is evaluated and thrown away. i ends up being one, not two. In a posting on Usenet some years ago, Dennis Ritchie explained how some of these anomalies are historical accidents.
Software Dogma

'And' and 'AND' or 'Or' or 'OR'

From decvax!harpo!npoiv!alice!research!dmr

Date: Fri Oct 22 01:04:10 1982

Subject: Operator precedence

Newsgroups: net.lang.c

The priorities of && || vs. == etc. came about in the following way. Early C had no separate operators for & and && or | and ||. (Got that?) Instead it used the notion (inherited from B and BCPL) of "truth-value context": where a Boolean value was expected, after "if" and "while" and so forth, the & and | operators were interpreted as && and || are now; in ordinary expressions, the bitwise interpretations were used. It worked out pretty well, but was hard to explain. (There was the notion of "top-level operators" in a truth-value context.)

The precedence of & and | were as they are now. Primarily at the urging of Alan Snyder, the && and || operators were added. This successfully separated the concepts of bitwise operations and short-circuit Boolean evaluation. However, I had cold feet about the precedence problems. For example, there were lots of programs with things like if (a==b & c==d) ...

In retrospect it would have been better to go ahead and change the precedence of & to higher than ==, but it seemed safer just to split & and && without moving & past an existing operator. (After all, we had several hundred kilobytes of source code, and maybe 3 installations....)

Dennis Ritchie

Handy Heuristic

Order of Evaluation
The moral of all this is that you should always put parentheses around an expression that mixes Booleans, arithmetic, or bit-twiddling with anything else.
And remember that while precedence and associativity tell you what is grouped with what,

the order in which these groupings will be evaluated is always undefined. In the expression:
x = f() + g() * h();
The values returned by g() and h() will be grouped together for multiplication, but g and h might be called in any order. Similarly, f might be called before or after the multiplication, or even between g and h. All we can know for sure is that the multiplication will occur before the addition (because the result of the multiplication is one of the operands in the addition). It would still be poor style to write a program that relied on that knowledge. Most programming languages don't specify the order of operand evaluation. It is left undefined so that compiler-writers can take advantage of any quirks in the architecture, or special knowledge of values that are already in registers.
Pascal avoids all problems in this area by requiring explicit parentheses around expressions that mix Boolean operators and arithmetic operators. Some authorities recommend that there are only two precedence levels to remember in C: multiplication and division come before addition and subtraction. Everything else should be in parentheses. We think that's excellent advice.
Handy Heuristic
What "Associativity" Means
While the precedence of operators can be perplexing, many people are equally puzzled about the associativity of operators. Operator associativity never seems to be explained very clearly in the standard C literature. This handy heuristic explains what it is, and when you need to know about it. The five-cent explanation is that it is a "tie-breaker" for operators with equal precedence.
Every operator has a level of precedence and a "left" or "right" associativity assigned to it. The precedence indicates how "tightly" the operands in an unbracketed expression bind. For
example, in the expression a * b + c,since multiplication has a higher precedence than addition, it will be done first, and the multiplicand will be b, not b + c.
But many operators have the same precedence levels, and this is where associativity comes in. It is a protocol for explaining the real precedence among all operators that have the same apparent precedence level. If we have an expression like
int a, b=1, c=2; a = b = c;

we find that, since the expression only involves the assignment operator, precedence does not help us understand how the operands are grouped. So which happens first, the assignment of c to b, or the assignment of b to a? In the first case, a would be left with the value 2, and in the second case, a would end up as 1.
All assignment-operators have right associativity. The associativity protocol says that this means the rightmost operation in the expression is evaluated first, and evaluation proceeds from right to left. Thus, the value of c is assigned to b. Then the value of b is stored in a. a gets the value 2. Similarly, for operators with left associativity (such as the bitwise and's and or 's), the operands are grouped from left to right.
The only use of associativity is to disambiguate an expression of two or more equalprecedence operators. In fact, you'll note that all operators which share the same precedence level also share the same associativity. They have to, or else the expression evaluation would still be ambiguous. If you need to take associativity into account to figure out the value of an expression, it's usually better to rewrite the expression into two expressions, or to use parentheses.
The order in which things happen in C is defined for some things and not for others. The order of precedence and association are well-defined. However, the order of expression evaluation is mostly unspecified (the special term defined in the previous chapter) to allow compiler-writers the maximum
leeway to generate the fastest code. We say "mostly" because the order is defined for && and || and
a couple of other operators. These two evaluate their operands in a strict left-to-right order, stopping when the result is known. However, the order of evaluation of the arguments in a function call is another unspecified order.
The Early Bug gets() the Internet Worm
The problems in C are not confined to just the language. Some routines in the standard library have unsafe semantics. This was dramatically demonstrated in November 1988 by the worm program that wriggled through thousands of machines on the Internet network. When the smoke had cleared and the investigations were complete, it was determined that one way the worm had propagated was through a weakness in the finger daemon, which accepts queries over the network about who is currently logged
in. The finger daemon, in.fingerd, used the standard I/O routine gets().
The nominal task of gets() is to read in a string from a stream. The caller tells it where to put the incoming characters. But gets() does not check the buffer space; in fact, it can't check the buffer space. If the caller provides a pointer to the stack, and more input than buffer space, gets() will
happily overwrite the stack. The finger daemon contained the code:
main(argc, argv) char *argv[];
{ char line[512]; ... gets(line);

Here, line is a 512-byte array allocated automatically on the stack. When a user provides more input than that to the finger daemon, the gets() routine will keep putting it on the stack. Most
architectures are vulnerable to overwriting an existing entry in the middle of the stack with something bigger, that also overwrites neighboring entries. The cost of checking each stack access for size and permission would be prohibitive in software. A knowledgeable malefactor can amend the return address in the procedure activation record on the stack by stashing the right binary patterns in the argument string. This will divert the flow of execution not back to where it came from, but to a special
instruction sequence (also carefully deposited on the stack) that calls execv() to replace the
running image with a shell. Voilà, you are now talking to a shell on a remote machine instead of the finger daemon, and you can issue commands to drag across a copy of the virus to another machine. Repeat until sent to prison. Figure 2-2 shows the process.
Figure 2-2. How the Internet Worm Gained Remote Execution Privileges
Ironically, the gets() routine is an obsolete function that provided compatibility with the very first
version of the portable I/O library, and was replaced by standard I/O more than a decade ago. The
manpage even strongly recommends that fgets() always be used instead. The fgets() routine
sets a limit on the number of characters read, so it won't exceed the size of the buffer. The finger daemon was made secure with a two-line fix that replaced:
gets(line);
by the lines:
if (fgets(line, sizeof(line), stdin) == NULL) exit(1);
This swallows a limited amount of input, and thus can't be manipulated into overwriting important
locations by someone running the program. However, the ANSI C Standard did not remove gets()
from the language. Thus, while this particular program was made secure, the underlying defect in the C standard library was not removed.

Sins of Omission
The "sins of omission" category covers things that the language doesn't do that it should. This includes missing features like standard argument processing and the mistake of extracting lint checking from the compiler.
Mail Won't Go to Users with an "f" in Their User names
The bug report was very puzzling. It just said "mail isn't getting delivered to users who have an 'f' as the second character of their username." It sounded so unlikely. What could possibly cause mail to fail because of a character in the username? After all, there's no connection between the characters in a username and the mail delivery processing. Nonetheless, the problem was reported at multiple sites.
After some urgent testing, we found that mail was indeed falling into the void when an addressee had an "f" as the second character of the username! Thus, mail would go to Fred and Muffy, but not to Effie. An examination of the source code quickly located the trouble.
Many people are surprised to learn that ANSI C mandates the argc, argv convention of passing
arguments to a C program, but it does. The UNIX convention has been elevated to the level of a standard, and it was partly to blame for the mail bug here. The mail program had been amended in the previous release to:
if ( argv[argc-1][0] == '-' || (argv[argc-2][1] == 'f' ) ) readmail(argc, argv);
else sendmail(argc, argv);
The "mail" program can be executed either to send mail, or to read your incoming mail. We won't enquire too closely into the merits of making one program responsible for two such different tasks. This code was supposed to look at the arguments and use the information to decide if we are reading mail or sending mail. The way to distinguish is somewhat heuristic: look for switches that are unique to either reading or sending. In this case, if the final argument is a switch (i.e., starts with a hyphen), we are definitely reading mail. We are also reading mail if the last argument is not an option but is a
filename, that is, the next-to-last argument was "-f".
And this is where the programmer went wrong, aided by lack of support in the language. The programmer merely looked at the second character of the next-to-last option. If it was an "f", he assumed that mail was invoked with a line like:
mail -h -d -f /usr/linden/mymailbox
In most cases this was correct, and mail would be read from mymailbox. But it could also happen that the invocation was:
mail effie robert

In this case, the argument processing would make the mail program think it was being asked to read mail, not send it. Bingo! E-mail to users with an "f" as the second character of the name disappears! The fix was a one-liner: if you're looking at the next-to-last argument for a possible "f", make sure it is also preceded by a switch hyphen:
if ( argv[argc-1][0] == '-' || argv[argc-2][0] == '-' && (argv[argc-2][1] == 'f' ) ) readmail(argc, argv);
The problem was caused by bad parsing of arguments, but it was facilitated by inadequate classification of arguments between switches and filenames. Many operating systems (e.g., VAX/VMS) distinguish between runtime options and other arguments (e.g., filenames) to programs, but UNIX does not; nor does ANSI C.
Software Dogma
Shell Fumbles on Argument Parsing
The problem of inadequate argument parsing occurs in many places on UNIX. To find out which files in a directory are links, you might enter the command:
ls -l | grep ->
This will yield the error message "Missing name for redirect", and most people will quickly figure out that the right chevron has been interpreted by the shell as a redirection, not as an argument to grep. They will then hide it from the shell by quotes, and try this:
ls -l | grep "->"
Still no good! The grep program looks at the starting minus sign, interprets the argument as an unrecognized option of greater-than, and quits. The answer is to step back from "ls" and instead use:
file -h * | grep link
Many people have been tormented by creating a file the name of which starts with a hyphen, and then being unable to get rm to remove it. One solution in this case is to give the entire pathname of the file, so that rm does not see a leading hyphen and try to interpret the name as an option.

Some C programmers have adopted the convention that an argument of " -- " means "from this point
on, no arguments are switches, even if they start with a hyphen." A better solution would put the burden on the system, not the user, with an argument pro-cessor that divides arguments into options and non-options. The simple argv mechanism is now too well entrenched for any changes. Just don't send mail to Effie under pre-1990 versions of Berkeley UNIX.

Space—The Final Frontier

A lot of people will tell you that white space isn't significant in C; that you can have as much or as little of it as you like. Not so! Here are some examples where white space rad-ically changes the meaning or validity of a program.

• The backslash character can be used to "escape" several characters, including a newline. An

escaped newline is treated as one logical line, and this can be used to continue long strings. A

problem arises if you inadvertently slip a space or two in between the backslash and the
carriage return, as \ whitespace newline is different than \newline. This error can be hard to

find, as you are looking for something invisible (the presence of a space character where a

newline was intended). A newline is typically escaped to continue a multiline macro

definition. If your compiler doesn't have excellent error messages, you might as well give up

now. Another reason to escape a newline is to continue a string literal, like this:

•

•

char a[]= "Hi! How are you? I am quite a \

long string, folded onto 2 lines";

The problem of multiline string literals was addressed by ANSI C introducing the convention that adjacent string literals are glued together. As we point out elsewhere in this chapter, that approach solved one potential problem at the expense of introducing another.

• If you squeeze spaces out altogether, you can still run into trouble. For example, what do you think the following code means?
•
z = y+++x;

The programmer might have meant z = y + ++x, or equally could have had z = y++ + x in mind. The ANSI standard specifies a convention that has come to be known as the
maximal munch strategy. Maximal munch says that if there's more than one possibility for the next token, the compiler will prefer to bite off the one involving the longest sequence of
characters. So the above example will be parsed as z = y++ + x.

This can still lead to trouble, as the code

z = y+++++x;
will therefore be parsed as z = y++ ++ + x, and cause a compilation error along the
lines of "++ operator is floating loose in space". This will happen even though the compiler
could, in theory, have deduced that the only valid arrangement of spaces is z = y++ + ++x.

• Yet a third white space problem occurred when a programmer had two pointers-to-int, and wanted to divide one int by the other. The code said
•
ratio = *x/*y;
but the compiler issued an error message complaining of syntax error. The problem was the
lack of space between the "/ " division operator and the "* " indirection operator. When put
next to each other they opened a comment, and hid all the code up to the next closing comment!
Related to opening a comment without intending to, is the case of accidentally not closing a comment when you did mean to. One release of an ANSI C compiler had an interesting bug. The symbol table was accessed by a hash function that computed a likely place from which to start a serial search. The computation was copiously commented, even describing the book the algorithm came from. Unfortunately, the programmer omitted to close the comment! The entire hash initial value calculation thus fell inside the continuing comment, resulting in the code shown below. Make sure you can identify the problem and try to predict what happened.

int hashval=0; /* PJW hash function from "Compilers: Principles, and Tools"
* by Aho, Sethi, and Ullman, Second Edition. while (cp < bound) {
unsigned long overflow;

Techniques,

hashval = ( hashval <<4)+*cp++;

if ((overflow = hashval & (((unsigned long) 0xF) << 28)) != 0)

hashval ^= overflow | (overflow >> 24);

}

hashval %= ST_HASHSIZE;

/* choose start bucket */

/* Look through each table, in turn, for the name. If we fail,

* save the string, enter the string's pointer, and return it.

*/

for (hp = &st_ihash; ; hp = hp->st_hnext) {

int probeval = hashval; /* next probe value */

The entire calculation of the initial hash value was omitted, so the table was always searched serially from the zeroth element! As a result, symbol table lookup (a very frequent operation in a compiler) was much slower than it should have been. This was never found during testing because it only affected the speed of a lookup, not the result. This is why some compilers complain if they notice an opening comment in a comment string. The error was eventually found in the course of looking for a different bug. Inserting the closing comment resulted in an immediate compilation speedup of 15%!

A Digression into C++ Comments

C++ doesn't address most of the flaws of C, but it could have avoided this inadvertent run-on
comment. As in BCPL, C++ comments are introduced by // and go to the end of a line.

It was originally thought that the // comment convention would not alter the meaning of any
syntactically correct C code. Sadly, this is not so
a //* //*/ b is a/b in C, but is a in C++. The C++ language allows the C notation for comments, too.
The Compiler Date Is Corrupted
The bug described in this section is a perfect example of how easy it is to write something in C that happily compiles, but produces garbage at runtime. This can be done in any language (e.g., simply divide by zero), but few languages offer quite so many fruitful and inadvertent opportunities as C.
Sun's Pascal compiler had been newly "internationalized," that is, adapted so that (among other things) it would print out dates on source listings in the local format. Thus, in France the date might appear as
Lundi 6 Avril 1992. This was achieved by having the compiler first call stat() to obtain the sourcefile modification time in UNIX format, then call localtime() to convert it to a struct tm, and then finally call the strftime() string-from-time function to convert the struct tm time to an
ASCII string in local format.
Unhappily, there was a bug that showed up as a corrupted date string. The date was actually coming out not as
Lundi 6 Avril 1992 but rather in a corrupted form, as
Lui*7& %' Y sxxdj @ ^F
The function only has four statements, and the arguments to the function calls are correct in all cases. See if you can identify the cause of the string corruption.
/* Convert the source file timestamp into a localized date string */ char * localized_time(char * filename) {
struct tm *tm_ptr; struct stat stat_block; char buffer[120];
/* get the sourcefile's timestamp in time_t format */ stat(filename, &stat_block);
/* convert UNIX time_t into a struct tm holding local time */
tm_ptr = localtime(&stat_block.st_mtime);

/* convert the tm struct into a string in local format */ strftime(buffer, sizeof(buffer), "%a %b %e %T %Y", tm_ptr);

return buffer; }

See it? Time's up! The problem is in the final line of the function, where the buffer is returned. The buffer is an automatic array, local to this function. Automatic variables go away once the flow of control leaves the scope in which they are declared. That means that even if you return a pointer to such a variable, as here, there's no telling what it points to once the function is exited.

In C, automatic variables are allocated on the stack. This is explained at greater length in Chapter 6. When their containing function or block is exited, that portion of the stack is available for reuse, and will certainly be overwritten by the next function to be called. Depending on where in the stack the previous auto variable was and what variables the active function declares and writes, it might be overwritten immediately, or later, leading to a hard-to-find corruption problem.

There are several possible solutions to this problem.

1. Return a pointer to a string literal. Example:
2. char *func() { return "Only works for simple strings"; }

This is the simplest solution, but it can't be used if you need to calculate the string contents, as in this case. You can also get into trouble if string literals are stored in read-only memory, and the caller later tries to overwrite it.

3. Use a globally declared array. Example:

4.

5. char *func() {

6.

...

7. my_global_array[i] =

8.

...

9. return my_global_array;

}

This works for strings that you need to build up, and is still simple and easy to use. The disadvantages are that anyone can modify the global array at any time, and the next call to the function will overwrite it.

10. Use a static array. Example:

11.

12. char *func() {

13. static char buffer[20] ;

14.

...

15. return buffer;

}

This solves the problem of anyone overwriting the string. Only routines to which you give a pointer will be able to modify this static array. However, callers have to use the value or copy it before another call overwrites it. As with global arrays, large buffers can be wasteful of memory if not in use.

16. Explicitly allocate some memory to hold the return value. Example:
17. 18. char *func() { 19. char *s = malloc( 120 ) ; 20. ... 21. return s;
}

This method has the advantages of the static array, and each invocation creates a new buffer, so subsequent calls don't overwrite the value returned by the first. It works for multithreaded code (programs where there is more than one thread of control active at a given instant). The disadvantage is that the programmer has to accept responsibility for memory management. This may be easy, or it may be very hard, depending on the complexity of the program. It can lead to incredible bugs if memory is freed while still in use, or "memory leaks" if memory no longer in use is still held. It's too easy to forget to free allocated memory.

22. Probably the best solution is to require the caller to allocate the memory to hold the return

value. For safety, provide a count of the size of the buffer (just as fgets() requires in the

standard library).

23.

24. void func( char * result, int size) {

25.

...

26. strncpy(result,"That'd be in the data segment, Bob",

size);

27. }

28.

29. buffer = malloc(size);

30. func( buffer, size );

31.

...

free(buffer);

Memory management works best if you can write the "free" at the same time as you write the "malloc". This solution makes that possible.

To avoid the "data corruption" problem, note that lint will complain about the simplest case of:

return local_array;
saying warning: function returns pointer to automatic. However, neither
a compiler nor lint can detect all cases of a local array being returned (it may be hidden by a level of indirection).

Lint Should Never Have Been Separated Out
You'll notice a consistent theme running through many of the above problems: lint detects them and warns you. It takes discipline to ensure that code is kept lint clean, and it would save much trouble if the lint warnings were automatically generated by the compiler.
Back in the early days of C on UNIX, an explicit decision was made to extract full semantic checking from the compiler. This error checking was instead done by a stand-alone program known as "lint". By omitting comprehensive error-checking, the compiler could be made smaller, faster, and simpler. After all, programmers can always be trusted to say what they mean, and mean what they say, right? Wrong!
Handy Heuristic
Lint Early, Lint Often
Lint is your software conscience. It tells you when you are doing bad things. Always use lint. Listen to your conscience.
Separating lint out from the compiler as an independent program was a big mistake that people are only now coming to terms with. It's true that it made the compiler smaller and more focused, but it was at the grievous cost of allowing bugs and dubious code idioms to lurk unnoticed. Many, perhaps most, programmers do not use lint by default after each and every compilation. It's a poor trade-off to have buggy code compiled fast. Much of lint's checking is now starting to appear in compilers again.
However, there is one thing that lint commonly does that most C compiler implementations currently do not; namely, check for consistency of function use across multiple files. Many people regard this as a deficiency of compiler implementation, rather than a justifi-cation for a freestanding lint program. All Ada compilers do this multifile consistency checking; it is the trend in C++ translators, and perhaps eventually will be usual in C, too.
The SunOS Lint Party
The SunOS development team is justly proud of our lint-clean kernel. We'd paid a lot of attention to getting the 4.x kernel to pass through lint with no errors, and we kept it that way. When we changed our source base from BSD UNIX to SVR4 in 1991, we inherited a new kernel whose lint status was unknown. We decided to lint the SVR4 kernel.
This activity took place over several weeks and was known as the "lint party." It yielded about 12,000 unique lint warnings, each of which had to be investigated and corrected manually. By the end, changes had been made to about 750 source files, and the task had become known as "the lint merge from hell". Most of the lint messages just needed an

explicit cast, or lint comment, but there were several real bugs shaken out by the process:
• Argument types transposed between function and call • A function that was passed one argument, but expected three, and took junk off the
stack. Finding this cured an intermittent data corruption problem in the streams subsystem. • Variables used before being set.
The value is not just in removing existing bugs, but in preventing new bugs from contaminating the source base. We now keep the kernel lint-clean by requiring all source changes or additions to be run through lint and cstyle. In this way we have not only removed existing bugs, but are reducing the number of future bugs as well.
Some programmers strenuously object to the idea of putting lint back into the compiler on the grounds that it slows the compiler down and produces too many spurious warnings. Unfortunately, experience has proven repeatedly that making lint a separate tool mostly results in lint not being used.
The economics of software is such that the earlier in the development cycle a bug is found, the cheaper it is to fix. So it is a good investment to have lint (or preferably the compiler itself) do the extra work to find problems rather than the debugger; but better a debugger find the problems than an internal test group. The worst option of all is to leave the problems to be found by customers.
Some Light Relief—Some Features Really Are Bugs!
This chapter wouldn't be complete without finishing the story of space missions and software. The
Fortran DO loop story (which began this chapter and arose in the context of Mercury suborbital flights)
is frequently, and wrongly, linked with the Mariner 1 mission.
By coincidence, Mariner 1 was involved with a dramatic software failure, but it happened in quite a different manner, and was entirely unrelated to choice of language. Mariner 1 was launched in July 1962 to carry a probe to Venus, but had to be destroyed a few minutes after launch when its Atlas rocket started to veer off course.
After weeks of analysis, it was determined that the problem was in the software, but it was a transcription error in the algorithm rather than a program bug. In other words, the program had done what the programmer had supposed, but he had been told the wrong thing in the specification! The tracking algorithm was intended to operate on smoothed (average) velocity. The mathematical symbol for this is a horizontal bar placed over the quantity to be smoothed. In the handwritten guidance equations supplied to the programmer, the bar was accidentally omitted.
The programmer followed the algorithm he had been given exactly, and used the raw velocity direct from radar instead of the smoothed velocity. As a result, the program saw minor fluctuations in rocket velocity and, in a classic negative feedback loop, caused genuine erratic behavior in its correction attempts. The faulty program had been present in previous missions, but this was the first time it had been executed. Previous flights had been controlled from the ground, but on this occasion an antenna failed, preventing the receipt of radio instructions and thus causing the on-board control software to be invoked.
Moral: Even if you could make your programming language 100% reliable, you would still be prey to catastrophic bugs in the algorithm.

We have long felt that programmers working on real-time control systems should have the privilege of taking the first ride on the operational prototype. In other words, if your code implements the life support systems on the space shuttle, then you get to be launched into space and debug any last minute glitches personally. This would surely bring a whole new focus to product quality. Table 2-2 shows some of the opportunities.

When
Summer 1961
July 22, 1962

Table 2-2. The Truth About Two Famous Space Software Failures

Mission

Error

Mercury . used instead of ,

Mariner "R" instead of " " written

1

in specification

Result
nothing; error found before flight
$12M rocket and probe destroyed

Cause Flaw in Fortran language
programmer followed error in specification

Let us give the last word in this chapter to a more modern story of space software mishaps, almost certainly apocryphal. On every space shuttle mission, there is a cargo manifest, or list of all items to be loaded on board the craft before launch. The manifest lists each item with its weight, and is vital for calculating the fuel and balancing the craft. It seems that before the maiden flight, a dock master was checking off certain items as they were loaded onto the shuttle. He checked off the computer systems, and then came to the manifest entry for the software. It showed the software as having zero weight, which caused a minor panic—after all, surely everything weighs something!
There was some frantic communication between the loading dock and the computer center before the problem was resolved, and the zero-weight software (bit patterns in memory) was allowed to pass! Of course, everyone knows that information has mass in a relativistic sense, but let's not ruin a good story with pedantry, eh?

References
Ceruzzi, Paul, Beyond the Limits—Flight Enters the Computer Age, Cambridge, MA, MIT Press,1989 Hill, Gladwyn, "For Want of Hyphen Venus Rocket is Lost," New York Times, July 28, 1962. Nicks, Oran W., Far Travelers—The Exploring Machines, NASA publication SP-480, 1985. "Venus Shot Fails as Rocket Strays," Associated Press, New York Times, July 23, 1962.

Chapter 3. Unscrambling Declarations in C
"The name of the song is called 'Haddocks' Eyes.'" "Oh, that's the name of the song, is it?" Alice said trying to feel interested. "No, you don't understand," the Knight said, looking a little vexed. "That's what the name is called. The name really is 'The Aged Aged Man.'" "Then I ought to have said 'That's what the song is called'?" Alice corrected herself.

"No, you oughtn't: that's quite another thing! The song is called 'Ways and Means': but that's only what it's called, you know!"
"Well, what is the song, then?" said Alice, who was by this time completely bewildered.
"I was coming to that," the Knight said. "The song really is 'A-sitting On A Gate': and the tune's my own invention."
—Lewis Carroll, Through the Looking Glass
syntax only a compiler could love…how a declaration is formed…a word about structs…a word about unions…a word about enums…the precedence rule…unscrambling C declarations by diagram…typedef can be your friend…difference between typedef and #define…what "typedef struct foo { ... foo } foo;" means…the piece of code that understandeth all parsing…some light relief— software to bite the wax tadpole
There's a story that Queen Victoria was so impressed by Alice in Wonderland that she requested copies of other books by Lewis Carroll. The queen did not realize that Lewis Carroll was the penname of Oxford mathematics professor Charles Dodgson. She was not amused when sniggering courtiers brought her several weighty volumes including The Condensation (Factoring) of Determinants. This story was much told in Victorian times, and Dodgson tried hard to debunk it:
"I take this opportunity of giving what publicity I can to my contradiction of a silly story, which has been going the round of the papers, about my having presented certain books to Her Majesty the Queen. It is so constantly repeated, and is such absolute fiction, that I think it worthwhile to state, once for all, that it is utterly false in every particular: nothing even resembling it has ever occurred."
—Charles Dodgson, Symbolic Logic, Second Edition
Therefore, on the "he doth protest too much" principle, we can be reasonably certain that the incident did indeed happen exactly as described. In any case, Dodgson would have got on well with C, and Queen Victoria would not. Putting the quote at the head of this chapter into a table, we get:

name of the song the song

is called "Haddocks' Eyes" "Ways and Means"

is "The Aged Aged Man" "A-sitting On A Gate"

Yes, Dodgson would have been right at home with computer science. And he would have especially appreciated type models in programming languages. For example, given the C declarations:

typedef char * string; string punchline = "I'm a frayed knot";
we can see how the Knight's paradigm can be applied to it:

type of the variable the variable

is called
string punchline

is
char * "I'm a frayed knot"

What could be more intuitive than that? Well, actually quite a lot of things, and they'll be clearer still after you've read this chapter.
Syntax Only a Compiler Could Love
As Kernighan and Ritchie acknowledge, "C is sometimes castigated for the syntax of its declarations" (K&R, 2nd E.d, p. 122). C's declaration syntax is trivial for a compiler (or compiler-writer) to process, but hard for the average programmer. Language designers are only human, and mistakes will be made. For example, the Ada language reference manual gives an ambiguous grammar for Ada in an appendix at the back. Ambiguity is a very undesirable property of a programming language grammar, as it significantly com-plicates the job of a compiler-writer. But the syntax of C declarations is a truly horrible mess that permeates the use of the entire language. It's no exaggeration to say that C is significantly and needlessly complicated because of the awkward manner of combining types.
There are several reasons for C's difficult declaration model. In the late 1960s, when this part of C was designed, "type models" were not a well understood area of programming language theory. The BCPL language (the grandfather of C) was type-poor, having the binary word as its only data type, so C drew on a base that was deficient. And then, there is the C philosophy that the declaration of an object
should look like its use. An array of pointers-to-integers is declared by int * p[3]; and an integer is referenced or used in an expression by writing *p[i], so the declaration resembles the use.
The advantage of this is that the precedence of the various operators in a "declaration" is the same as in a "use". The disadvantage is that operator precedence (with 15 or more levels in the hierarchy, depending on how you count) is another unduly complicated part of C. Programmers have to
remember special rules to figure out whether int *p[3] is an array of pointers-to-int, or a pointer
to an array of ints.
The idea that a declaration should look like a use seems to be original with C, and it hasn't been adopted by any other languages. Then again, it may be that declaration looks like use was not quite the splendid idea that it seemed at the time. What's so great about two different things being made to look the same? The folks from Bell Labs acknowledge the criticism, but defend this decision to the death even today. A better idea would have been to declare a pointer as
int &p; which at least suggests that p is the address of an integer. This syntax has now been claimed by C++ to indicate a call by reference parameter.
The biggest problem is that you can no longer read a declaration from left to right, as people find most
natural. The situation got worse with the introduction of the volatile and const keywords with
ANSI C; since these keywords appear only in a declaration (not in a use), there are now fewer cases in which the use of a variable mimics its declaration. Anything that is styled like a declaration but doesn't have an identifier (such as a formal parameter declaration or a cast) looks funny. If you want to cast something to the type of pointer-to-array, you have to express the cast as:
char (*j)[20]; /* j is a pointer to an array of 20 char */ j = (char (*)[20]) malloc( 20 );
If you leave out the apparently redundant parentheses around the asterisk, it becomes invalid.

A declaration involving a pointer and a const has several possible orderings:
const int * grape; int const * grape; int * const grape_jelly;
The last of these cases makes the pointer read-only, whereas the other two make the object that it points at read-only; and of course, both the object and what it points at might be constant. Either of the following equivalent declarations will accomplish this:
const int * const grape_jam; int const * const grape_jam;
The ANSI standard implicitly acknowledges other problems when it mentions that the typedef specifier is called a "storage-class specifier" for syntactic convenience only. It's an area that even experienced C programmers find troublesome. If declaration syntax looks bad for something as straightforward as an array of pointers, consider how it looks for something even slightly complicated.
What exactly, for example, does the following declaration (adapted from the telnet program)
declare?
char* const *(*next)();
We'll answer the question by using this declaration as an example later in the chapter. Over the years, programmers, students, and teachers have struggled to find simple mnemonics and algorithms to help them make some sense of the horrible C syntax. This chapter presents an algorithm that gives a stepby-step approach to solving the problem. Work through it with a couple of examples, and you'll never have to worry about C declarations again!
How a Declaration Is Formed
Let's first take a look at some C terminology, and the individual pieces that can make up a declaration. An important building block is a declarator—the heart of any declaration; roughly, a declarator is the identifier and any pointers, function brackets, or array indica-tions that go along with it, as shown in Figure 3-1. We also group any initializer here for convenience.
Figure 3-1. The Declarator in C

A declaration is made up of the parts shown in Figure 3-2 Figure 3-2(not all combinations are valid, but this table gives us the vocabulary for further discussion). A declaration gives the basic underlying type of the variable and any initial value.
Figure 3-2. The Declaration in C
We begin to see how complicated a declaration can become once you start combining types together. Also, remember there are restrictions on legal declarations. You can't have any of these:
• a function can't return a function, so you'll never see foo()() • a function can't return an array, so you'll never see foo()[] • an array can't hold a function, so you'll never see foo[]()
You can have any of these:
• a function returning a pointer to a function is allowed: int (* fun())(); • a function returning a pointer to an array is allowed: int (* foo())[] • an array holding pointers to functions is allowed: int (*foo[])()

• an array can hold other arrays, so you'll frequently see int foo[][]
Before dealing with combining types, we'll refresh our memories by reviewing how to combine variables in structs and unions, and also look at enums.
A Word About structs
Structs are just a bunch of data items grouped together. Other languages call this a "record". The syntax for structs is easy to remember: the usual way to group stuff together in C is to put it in braces:
{ stuff... } The keyword struct goes at the front so the compiler can distinguish it from a block:

struct {stuff... }
The stuff in a struct can be any other data declarations: individual data items, arrays, other structs, pointers, and so on. We can follow a struct definition by some variable names, declaring variables of this struct type, for example:

struct {stuff... } plum, pomegranate, pear;
The only other point to watch is that we can write an optional "structure tag" after the keyword "struct":

struct fruit_tag {stuff... } plum, pomegranate, pear; The words struct fruit_tag can now be used as a shorthand for

struct {stuff... } in future declarations.
A struct thus has the general form:

struct

optional_tag { type_1 identifier_1; type_2 identifier_2; ... type_N identifier_N; } optional_variable_definitions;

So with the declarations

struct date_tag { short dd,mm,yy; } my_birthday, xmas; struct date_tag easter, groundhog_day;

variables my_birthday, xmas, easter, and groundhog_day all have the identical type. Structs can also have bit fields, unnamed fields, and word-aligned fields. These are obtained by following the field declaration with a colon and a number representing the field length in bits.

/* process ID info */

struct pid_tag {

unsigned int inactive :1;

unsigned int

:1;

unsigned int refcount :6;

unsigned int

:0;

*/

short pid_id;

struct pid_tag *link;

};

/* 1 bit of padding */ /* pad to next word boundary

This is commonly used for "programming right down to the silicon," and you'll see it in systems programs. It can also be used for storing a Boolean flag in a bit rather than a char. A bit field must have a type of int, unsigned int, or signed int (or a qualified version of one of these). It's implementation-dependent whether bit fields that are int's can be negative.

Our preference is not to mix a struct declaration with definitions of variables. We prefer

struct veg { int weight, price_per_lb; }; struct veg onion, radish, turnip; to
struct veg { int weight, price_per_lb; } onion, radish, turnip;
Sure, the second version saves you typing a few characters of code, but we should be much more concerned with how easy the code is to read, not to write. We write code once, but it is read many times during subsequent program maintenance. It's just a little simpler to read a line that only does one thing. For this reason, variable declarations should be separate from the type declaration.
Finally there are two parameter passing issues associated with structs. Some C books make statements like "parameters are passed to a called function by pushing them on the stack from right to left." This is oversimplification—if you own such a book, tear out that page and burn it. If you own such a compiler, tear out those bytes. Parameters are passed in registers (for speed) where possible. Be aware that an int "i" may well be passed in a completely different manner to a struct "s" whose only member is an int. Assuming an int parameter is typically passed in a register, you may find that structs are instead passed on the stack. The second point to note is that by putting an array inside a struct like this:

/* array inside a struct */ struct s_tag { int a[100]; };
you can now treat the array as a first-class type. You can copy the entire array with an assignment statement, pass it to a function by value, and make it the return type of a function.

struct s_tag { int a[100]; }; struct s_tag orange, lime, lemon; struct s_tag twofold (struct s_tag s) {
int j; for (j=0;j<100;j++) s.a[j] *= 2; return s; }
main() { int i; for (i=0;i<100;i++) lime.a[i] = 1; lemon = twofold(lime); orange = lemon; /* assigns entire struct */
}
You typically don't want to assign an entire array very often, but you can do it by burying it in a struct. Let's finish up by showing one way to make a struct contain a pointer to its own type, as needed for lists, trees, and many dynamic data structures.

/* struct that points to the next struct */

struct node_tag { int datum;

struct node_tag *next;

};

struct node_tag a,b;

a.next = &b;

/* example link-up */

a.next->next=NULL;

A Word About unions

Unions are known as the variant part of variant records in many other languages. They have a similar appearance to structs, but the memory layout has one crucial difference. Instead of each member being stored after the end of the previous one, all the members have an offset of zero. The storage for the individual members is thus overlaid: only one member at a time can be stored there.

There's some good news and some bad news associated with unions. The bad news is that the good news isn't all that good. The good news is that unions have exactly the same general appearance as
structs, but with the keyword struct replaced by union. So if you're comfortable with all the
varieties and possibilities for structs, you already know unions too. A union has the general form:

union optional_tag { type_1 identifier_1; type_2 identifier_2; ... type_N identifier_N;
} optional_variable_definitions;

Unions usually occur as part of a larger struct that also has implicit or explicit information about which type of data is actually present. There's an obvious type insecurity here of storing data as one type and retrieving it as another. Ada addresses this by insisting that the discriminant field be explicitly stored in the record. C says go fish, and relies on the programmer to remember what was put there.
Unions are typically used to save space, by not storing all possibilities for certain data items that cannot occur together. For example, if we are storing zoological information on certain species, our first attempt at a data record might be:

struct creature { char has_backbone; char has_fur; short num_of_legs_in_excess_of_4;
};
However, we know that all creatures are either vertebrate or invertebrate. We further know that only vertebrate animals have fur, and that only invertebrate creatures have more than four legs. Nothing has more than four legs and fur, so we can save space by storing these two mutually exclusive fields as a union:

union secondary_characteristics { char has_fur; short num_of_legs_in_excess_of_4;
}; struct creature {
char has_backbone; union secondary_characteristics };

form;

We would typically overlay space like this to conserve backing store. If we have a datafile of 20 million animals, we can save up to 20 Mb of disk space this way.

There is another use for unions, however. Unions can also be used, not for one interpretation of two different pieces of data, but to get two different interpretations of the same data. Interestingly enough, this does exactly the same job as the REDEFINES clause in COBOL. An example is:

union bits32_tag {

int whole;

/* one 32-bit value

*/

struct {char c0,c1,c2,c3;} byte; /* four 8-bit bytes

*/

} value;

This union allows a programmer to extract the full 32-bit value, or the individual byte fields
value.byte.c0, and so on. There are other ways to accomplish this, but the union does it
without the need for extra assignments or type casting. Just for fun, I looked through about 150,000

lines of machine-independent operating system source (and boy, are my arms tired). The results showed that structs are about one hundred times more common than unions. That's an indication of how much more frequently you'll encounter structs than unions in practice.
A Word About enums
Enums (enumerated types) are simply a way of associating a series of names with a series of integer values. In a weakly typed language like C, they provide very little that can't be done with a
#define, so they were omitted from most early implementations of K&R C. But they're in most
other languages, so C finally got them too. The general form of an enum should look familiar by now:
enum optional_tag {stuff... } optional_variable_definitions;
The stuff… in this case is a list of identifiers, possibly with integer values assigned to them. An enumerated type example is:
enum sizes { small=7, medium, large=10, humungous };
The integer values start at zero by default. If you assign a value in the list, the next value is one greater, and so on. There is one advantage to enums: unlike #defined names which are typically discarded during compilation, enum names usually persist through to the debugger, and can be used while debugging your code.
The Precedence Rule
We have now reviewed the building blocks of declarations. This section describes one method for breaking them down into an English explanation. The precedence rule for understanding C declarations is the one that the language lawyers like best. It's high on brevity, but very low on intuition.
The Precedence Rule for Understanding C Declarations A Declarations are read by starting with the name and then reading in precedence order. B The precedence, from high to low, is:
B.1 parentheses grouping together parts of a declaration B.2 the postfix operators:
parentheses () indicating a function, and
square brackets [] indicating an array.
B.3 the prefix operator: the asterisk denoting "pointer to".
C If a const and/or volatile keyword is next to a type specifier (e.g. int, long, etc.) it applies to the type specifier. Otherwise the const and/or volatile keyword applies to the
pointer asterisk on its immediate left.
An example of solving a declaration using the Precedence Rule:

char* const *(*next)();

Rule to apply A
B.1 B
B.2
B.3 C

Table 3-1. Solving a Declaration Using the Precedence Rule
Explanation
First, go to the variable name, "next", and note that it is directly enclosed by
parentheses.
So we group it with what else is in the parentheses, to get "next is a pointer to...".
Then we go outside the parentheses, and have a choice of a prefix asterisk, or a postfix pair of parentheses. Rule B.2 tells us the highest precedence thing is the function parentheses at the right, so
we have "next is a pointer to a function returning…" Then process the prefix "*" to get "pointer to". Finally, take the "char * const", as a constant pointer to a character.

Then put it all together to read:

"next is a pointer to a function returning a pointer to a const pointer-to-char"
and we're done. The precedence rule is what all the rules boil down to, but if you prefer something a little more intuitive, use Figure 3-3.
Figure 3-3. How to Parse a C Declaration

Unscrambling C Declarations by Diagram
In this section we present a diagram with numbered steps (see Figure 3-3). If you proceed in steps, starting at one and following the guide arrows, a C declaration of arbitrary complexity can quickly be translated into English (also of arbitrary complexity). We'll simplify declarations by ignoring typedefs in the diagram. To read a typedef, translate the declaration ignoring the word "typedef". If it translates to "p is a…", you can now use the name "p" whenever you want to declare something of the type to which it translates.
Magic Decoder Ring for C Declarations
Declarations in C are read boustrophedonically,i.e. alternating right-to-left with left-to right. And who'd have thought there would be a special word to describe that! Start at the first identifier you find when reading from the left. When we match a token in our declaration against the diagram, we erase it from further consideration. At each point we look first at the token to the right, then to the left. When everything has been erased, the job is done.

Let's try a couple of examples of unscrambling a declaration using the diagram. Say we want to figure out what our first example of code means:

char* const *(*next)();
As we unscramble this declaration, we gradually "white out" the pieces of it that we have already dealt
with, so that we can see exactly how much remains. Again, remember const means "read-only".
Just because it says constant, it doesn't necessarily mean constant.
The process is represented in Table 3-2. In each step, the portion of the declaration we are dealing with is printed in bold type. Starting at step one, we will proceed through these steps.

Table 3-2. Steps in Unscrambling a C Declaration

Declaration Remaining
(start at leftmost identifier)
char * const *(*next )(); char * const *(*) ();
char * const *(* )(); char * const *(* )();
char * const *() (); char * const * () ; char * const * () ; char * const * ; char * const * ; char * const ; char * ; char ;

Next Step to Apply

Result

step 1

say "next is a…"

step 2, 3
step 4 step 5
step 4 step 2 step 3 step 4 step 5 step 5 step 5 step 6

doesn't match, go to next step, say "next is a…" doesn't match, go to next step asterisk matches, say "pointer to …", go to step 4 "(" matches up to ")", go to step 2 doesn't match, go to next step say "function returning…" doesn't match, go to next step say "pointer to…" say "read-only…" say "pointer to…" say "char"

Then put it all together to read:

"next is a pointer to a function returning a pointer to a read-only pointer-to-char"

and we're done. Now let's try a more complicated example.

char *(*c[10])(int **p);

Try working through the steps in the same way as the last example. The steps are given at the end of this chapter, to give you a chance to try it for yourself and compare your answer.
typedef Can Be Your Friend
Typedefs are a funny kind of declaration: they introduce a new name for a type rather than reserving space for a variable. In some ways, a typedef is similar to macro text replacement—it doesn't introduce a new type, just a new name for a type, but there is a key difference explained later.
If you refer back to the section on how a declaration is formed, you'll see that the typedef keyword
can be part of a regular declaration, occurring somewhere near the beginning. In fact, a typedef has exactly the same format as a variable declaration, only with this extra keyword to tip you off.
Since a typedef looks exactly like a variable declaration, it is read exactly like one. The techniques given in the previous sections apply. Instead of the declaration saying "this name refers to a variable
of the stated type," the typedef keyword doesn't create a variable, but causes the declaration to say
"this name is a synonym for the stated type."
Typically, this is used for tricky cases involving pointers to stuff. The classic example is the
declaration of the signal() prototype. Signal is a system call that tells the runtime system to call a
particular routine whenever a specified "software interrupt" arrives. It should really be called
"Call_that_routine_when_this_interrupt_comes_in". You call signal() and pass it arguments to
say which interrupt you are talking about, and which routine should be invoked to handle it. The ANSI Standard shows that signal is declared as:

void (*signal(int sig, void (*func)(int)) ) (int);
Practicing our new-found skills at reading declarations, we can tell that this means:

void (*signal(

) ) (int);

signal is a function (with some funky arguments) returning a pointer to a function (taking an int
argument and returning void). One of the funky arguments is itself:

void (*func)(int) ;
a pointer to a function taking an int argument and returning void. Here's how it can be simplified by a typedef that "factors out" the common part.

typedef void (*ptr_to_func) (int); /* this says that ptr_to_func is a pointer to a function
* that takes an int argument, and returns void */

ptr_to_func signal(int, ptr_to_func); /* this says that signal is a function that
* two arguments, an int and a ptr_to_func, * returns a ptr_to_func */

takes and

Typedef is not without its drawbacks, however. It has the same confusing syntax of other declarations, and the same ability to cram several declarators into one declaration. It provides essentially nothing
for structs, except the unhelpful ability to omit the struct keyword. And in any typedef, you don't even have to put the typedef at the start of the declaration!

Handy Heuristic

Tips for Working with Declarators Don't put several declarators together in one typedef, like this:

typedef int *ptr, (*fun)(), arr[5]; /* ptr is the type "pointer to int"
* fun is the type "pointer to a function * arr is the type "array of 5 ints" */

returning

int"

And never, ever, bury the typedef in the middle of a declaration, like this:

unsigned const long typedef int volatile *kumquat;
Typedef creates aliases for data types rather than new data types. You can typedef any type.

typedef int (*array_ptr)[100];
Just write a declaration for a variable with the type you desire. Have the name of the variable be the name you want for the alias. Write the keyword 'typedef ' at the start, as shown above. A typedef name cannot be the same as another identifier in the same block.

Difference Between typedef int x[10] and #define x int[10]
As mentioned above, there is a key difference between a typedef and macro text replacement. The right way to think about this is to view a typedef as being a complete "encapsulated" type—you can't add to it after you have declared it. The difference between this and macros shows up in two ways. You can extend a macro typename with other type specifiers, but not a typedef 'd typename. That is,
#define peach int unsigned peach i; /* works fine */ typedef int banana; unsigned banana i; /* Bzzzt! illegal */
Second, a typedef 'd name provides the type for every declarator in a declaration.
#define int_ptr int * int_ptr chalk, cheese;
After macro expansion, the second line effectively becomes:
int * chalk, cheese;
This makes chalk and cheese as different as chutney and chives: chalk is a pointer-to-an-integer, while cheese is an integer. In contrast, a typedef like this:
typedef char * char_ptr; char_ptr Bentley, Rolls_Royce;
declares both Bentley and Rolls_Royce to be the same. The name on the front is different, but they are both a pointer to a char.
What typedef struct foo { ... foo; } foo; Means
There are multiple namespaces in C: * label names * tags (one namespace for all structs, enums and unions) * member names (each struct or union has its own namespace) * everyting else

Everything within a namespace must be unique, but an identical name can be applied to things in different namespaces. Since each struct or union has its own namespace, the same member names can be reused in many different structs. This was not true for very old compilers, and is one reason people prefixed field names with a unique initial in the BSD 4.2 kernel code, like this:

struct };

vnode { long long struct struct

vnode vnodeops

v_flag; v_usecount; *v_freef; *v_op;

Because it is legal to use the same name in different namespaces, you sometimes see code like this.

struct foo {int foo;} foo;
This is absolutely guaranteed to confuse and dismay future programmers who have to maintain your
code. And what would sizeof( foo ); refer to?
Things get even scarier. Declarations like these are quite legal:

typedef struct baz {int baz;} baz; struct baz variable_1; baz variable_2;
That's too many "baz"s! Let's try that again, with more enlightening names, to see what's going on:

typedef struct my_tag {int i;} my_type; struct my_tag variable_1;
my_type variable_2;
The typedef introduces the name my_type as a shorthand for "struct my_tag {int i}", but it also introduces the structure tag my_tag that can equally be used with the keyword struct.
If you use the same identifier for the type and the tag in a typedef, it has the effect of making the
keyword "struct" optional, which provides completely the wrong mental model for what is going
on. Unhappily, the syntax for this kind of struct typedef exactly mirrors the syntax of a combined struct type and variable declaration. So although these two declarations have a similar form,

typedef struct fruit {int weight, price_per_lb } fruit; /* statement 1 */
struct veg {int weight, price_per_lb } veg; /* statement 2 */ very different things are happening. Statement 1 declares a structure tag "fruit" and a structure typedef "fruit" which can be used like this:

struct fruit mandarin; /* uses structure tag "fruit" */ fruit tangerine; /* uses structure type "fruit" */
Statement 2 declares a structure tag "veg" and a variable veg. Only the structure tag can be used in further declarations, like this:

struct veg potato; It would be an error to attempt a declaration of veg cabbage. That would be like writing:

int i; ij;

Handy Heuristic

Tips for Working with Typedefs

Don't bother with typedefs for structs.

All they do is save you writing the word "struct", which is a clue that you probably shouldn't be hiding anyway.

Use typedefs for:

• types that combine arrays, structs, pointers, or functions.

• portable types. When you need a type that's at least (say) 20-bits, make it a typedef.

Then when you port the code to different platforms, select the right type, short,

int, long, making the change in just the typedef, rather than in every

declaration.

• casts. A typedef can provide a simple name for a complicated type cast. E.g.

•

• typedef int (*ptr_to_int_fun)(void);

•

char * p;

= (ptr_to_int_fun) p;

Always use a tag in a structure definition, even if it's not needed. It will be later.

A pretty good principle in computer science, when you have two different things, is to use two different names to refer to them. It reduces the opportunities for confusion (always a good policy in software). If you're stuck for a name for a structure tag, just give it a name that ends in "_tag". This

makes it simpler to detect what a particular name is. Future generations will then bless your name instead of reviling your works.
The Piece of Code that Understandeth All Parsing
You can easily write a program that parses C declarations and translates them into English. In fact, why don't you? The basic form of a C declaration has already been described. All we need to do is write a piece of code which understands that form and unscrambles it the same way as Figure 3-4. To keep it simple, we'll pretty much ignore error handling, and we'll deal with structs, enums, and unions by compressing them down to just the single word "struct", "enum" or "union". Finally, this program expects functions to have empty parentheses (i.e., no argument lists).
Programming Challenge
Write a Program to Translate C Declarations into English
Here's the design. The main data structure is a stack, on which we store tokens that we have read, while we are reading forward to the identifier. Then we can look at the next token to the right by reading it, and the next token to the left by popping it off the stack. The data structure looks like:
struct token { char type; char string[MAXTOKENLEN]; };
/* holds tokens we read before reaching first identifier */ struct token stack[MAXTOKENS];
/* holds the token just read */ struct token this;
The pseudo-code is:
utility routines----------
classify_string look at the current token and return a value of "type" "qualifier" or "identifier"
in this.type gettoken

read the next token into this.string if it is alphanumeric, classify_string else it must be a single character token this.type = the token itself; terminate this.string with a nul. read_to_first_identifier gettoken and push it onto the stack until the first identifier is read. Print "identifier is", this.string gettoken
parsing routines----------
deal_with_function_args read past closing ')' print out "function returning"
deal_with_arrays while you've got "[size]" print it out and read past
it deal_with_any_pointers
while you've got "*" on the stack print "pointer to" and pop it deal_with_declarator
if this.type is '[' deal_with_arrays if this.type is '(' deal_with_function_args deal_with_any_pointers while there's stuff on the stack if it's a '(' pop it and gettoken; it should be the closing ')' deal_with_declarator else pop it and print it
main routine----------
main read_to_first_identifier deal_with_declarator
This is a small program that has been written numerous times over the years, often under the name "cdecl". [1] An incomplete version of cdecl appears in The C Programming Language. The cdecl specified here is more complete; it supports the type qualifiers "const" and "volatile". It also knows about structs, enums, and unions though not in full generality; it is easy to extend this version to handle argument declarations in functions. This program can be implemented with about 150 lines of C. Adding error handling, and the full generality of declarations, would make it much larger. In any event, when you program this parser, you are implementing one of the major subsystems in a compiler—that's a substantial programming achievement, and one that will really help you to gain a deep understanding of this area.

[1] Don't confuse this with the cdecl modifier used in Turbo C on PC's to indicate that the generated code should not use the Turbo Pascal default convention for calling functions. The cdecl modifier allows Borland C code to be linked with other Turbo languages that were implemented with different calling conventions.
Further Reading
Now that you have mastered the way to build data structures in C, you may be interested in reading a good general-purpose book on data structures. One such book is Data Structures with Abstract Data Types by Daniel F. Stubbs and Neil W. Webre, 2nd Ed., Pacific Grove, CA, Brooks/Cole, 1989. They cover a wide variety of data structures, including strings, lists, stacks, queues, trees, heaps, sets, and graphs. Recommended.
Some Light Relief—Software to Bite the Wax Tadpole…
One of the great joys of computer programming is writing software that controls something physical (like a robot arm or a disk head). There's an enormous feeling of satisfaction when you run a program and something moves in the real world. The graduate students in MIT's Artificial Intelligence Laboratory were motivated by this when they wired up the departmental computer to the elevator call button on the ninth floor. This enabled you to call the elevator by typing a command from your LISP machine! The program checked to make sure your terminal was actually located inside the laboratory before it called the elevator, to prevent rival hackers using the dark side of the force to tie up the elevators.
The other great joy of computer programming is chowing down on junk food while hack-ing. So what could be more natural than to combine the two thrills? Some computer science graduate students at Carnegie-Mellon University developed a junk-food/com-puter interface to solve a long-standing problem: the computer science department Coke® machine was on the third floor, far from the offices of the graduate students. Students were fed up with travelling the long distance only to find the Coke machine empty or, even worse, so recently filled that it was dispensing warm bottles. John Zsarney and Lawrence Butcher noticed that the Coke machine stored its product in six refrigerated col-umns, each with an "empty" light that flashed as it delivered a bottle, and stayed on when the column was sold out. It was a simple matter to wire up these lights to a serial interface and thus transmit the "bottle dispensed" data to the PDP10 department mainframe computer. From the PDP10, the Coke machine interface looked just like a telnet connection! Mike Kazar and Dave Nichols wrote the software that responded to enquiries and kept track of which column contained the most refrigerated bottles.
Naturally, Mike and Dave didn't stop there. They also designed a network protocol that enabled the mainframe to respond to Coke machine status enquiries from any machine on the local ethernet, and eventually from the Internet itself. Ivor Durham implemented the software to do this and to check the Coke machine status from other machines. With admirable economy of effort Ivor reused the standard "finger" facility—normally used to check from one machine whether a specified user is logged onto another machine. He modified the "finger" server to run the Coke status program whenever someone fingered the nonexistent user "coke". Since finger requests are part of standard Internet protocols, people could check the Coke machine from any CMU computer. In fact, by running the command
finger coke@g.gp.cs.cmu.edu
you could discover the Coke machine's status from any machine anywhere on the Internet, even thousands of miles away!

Others who worked on the project include Steve Berman, Eddie Caplan, Mark Wilkins, and Mark Zaremsky [2]. The Coke machine programs were used for over a decade, and were even rewritten for UNIX Vaxen when the PDP-10 was retired in the early 1980s. The end came a few years ago, when the local Coke bottler discontinued the returnable, Coke-bottle-shaped bottles. The old machine couldn't handle the new shape bottles, so it was replaced by a new vending machine that required a new interface. For a while nobody bothered, but the lure of caffeine eventually motivated Greg Nelson to reengineer the new machine. The CMU graduate students also wired up the candy machine, and similar projects have been completed in other schools, too.
[2] Craig Everhart, Eddie Caplan, and Robert Frederking, "Serious Coke Addiction," 25th Anniversary Symposium, Computer Science at CMU: A Commemorative Review, 1990, p. 70. Reed and Witting Company.
The computer club at the University of Western Australia has a Coke machine connected to a 68000 CPU, with 80K of memory and an ethernet interface (more power than most PC's had a decade ago). The Computer Science House at Rochester Institute of Technology, Rochester, NY, also has a Coke machine on the Internet, and has extended it to providing drinks on credit and computerized account billing. One student enjoyed remote logging in from home hundreds of miles away over the summer, and randomly dispensing a few free drinks for whoever next passed. It's getting to the point where "Coke machine" will soon be the most common type of hardware on the Internet.
Why stop with cola? Last Christmas, programmers at Cygnus Support connected their office Christmas tree decorations to their ethernet. They could amuse themselves by tog-gling various lights from their workstations. And people worry that Japan is pulling ahead of America in technology! Inside Sun Microsystems, there's an e-mail address gate-wayed to a fax modem. When you send email there, it's parsed for phone number details and sent on as a fax transmission. Ace programmer Don Hopkins wrote pizzatool to put it to good use. Pizzatool let you custom-select toppings for a pizza using a GUI interface (most users specified extra GUI cheese), and sent the fax order to nearby Tony & Alba's Pizza restaurant, which accepted fax orders and delivered.
I don't think I'll be divulging a trade secret if I mention that extensive use was made of this service during the late-night lab sessions developing Sun's SPARCserver 600MP series machines. Bon appetit!
Programming Solution

The Piece of Code that Understandeth All 1 #include <stdio.h> 2 #include <string.h> 3 #include <ctype.h> 4 #include <stdlib.h> 5 #define MAXTOKENS 100 6 #define MAXTOKENLEN 64 7 8 enum type_tag { IDENTIFIER, QUALIFIER,

Parsing TYPE };

9

10 struct token {

11

char type;

12

char string[MAXTOKENLEN];

13 };

14

15 int top=-1;

16 struct token stack[MAXTOKENS];

17 struct token this;

18

19 #define pop stack[top--]

20 #define push(s) stack[++top]=s

21

22 enum type_tag classify_string(void)

23 /* figure out the identifier type */

24 {

25

char *s = this.string;

26

if (!strcmp(s,"const")) {

27

strcpy(s,"read-only");

28

return QUALIFIER;

29

}

30

if (!strcmp(s,"volatile")) return QUALIFIER;

31

if (!strcmp(s,"void")) return TYPE;

32

if (!strcmp(s,"char")) return TYPE;

33

if (!strcmp(s,"signed")) return TYPE;

34

if (!strcmp(s,"unsigned")) return TYPE;

35

if (!strcmp(s,"short")) return TYPE;

36

if (!strcmp(s,"int")) return TYPE;

37

if (!strcmp(s,"long")) return TYPE;

38

if (!strcmp(s,"float")) return TYPE;

39

if (!strcmp(s,"double")) return TYPE;

40

if (!strcmp(s,"struct")) return TYPE;

41

if (!strcmp(s,"union")) return TYPE;

42

if (!strcmp(s,"enum")) return TYPE;

43

return IDENTIFIER;

44 }

45

46 void gettoken(void) /* read next token into "this" */

47 {

48

char *p = this.string;

49

50

/* read past any spaces */

51

while ((*p = getchar()) == ' ' ) ;

52

53

if (isalnum(*p)) {

54

/* it starts with A-Z,0-9 read in identifier

*/

55

while ( isalnum(*++p=getchar()) );

56

ungetc(*p,stdin);

57

*p = '\0';

58

this.type=classify_string();

59

return;

60

}

61

62

if (*p=='*') {

63

strcpy(this.string,"pointer to");

64

this.type = '*';

65

return;

66

}

67

this.string[1]= '\0';

68

this.type = *p;

69

return;

70 }

71 /* The piece of code that understandeth all parsing.

*/

72 read_to_first_identifier() {

73

gettoken();

74

while (this.type!=IDENTIFIER) {

75

push(this);

76

gettoken();

77

}

78

printf("%s is ", this.string);

79

gettoken();

80 }

81

82 deal_with_arrays() {

83

while (this.type=='[') {

84

printf("array ");

85

gettoken(); /* a number or ']' */

86

if (isdigit(this.string[0])) {

87

printf("0..%d ",atoi(this.string)-1);

88

gettoken(); /* read the ']' */

89

}

90

gettoken(); /* read next past the ']' */

91

printf("of ");

92

}

93 }

94

95 deal_with_function_args() {

96

while (this.type!=')') {

97

gettoken();

98

}

99

gettoken();

100 printf("function returning ");

101 }

102

103 deal_with_pointers() {

104 while ( stack[top].type== '*' ) {

105

printf("%s ", pop.string );

106 }

107 }

108

109 deal_with_declarator() {

110 /* deal with possible array/function following

the identifier */

111 switch (this.type) {

112 case '[' : deal_with_arrays(); break;

113 case '(' : deal_with_function_args();

114 }

115

116 deal_with_pointers();

117

118 /* process tokens that we stacked while reading

to identifier */

119 while (top>=0) {

120

if (stack[top].type == '(' ) {

121

pop;

122

gettoken(); /* read past ')' */

123

deal_with_declarator();

124

} else {

125

printf("%s ",pop.string);

126

}

127 }

128 }

129

130 main()

131 {

132 /* put tokens on stack until we reach identifier

*/

133 read_to_first_identifier();

134 deal_with_declarator();

135 printf("\n");

136 return 0;

137 }

Handy Heuristic

Make String Comparison Look More Natural
One of the problems with the strcmp () routine to compare two strings is that it returns

zero if the strings are identical. This leads to convoluted code when the comparison is part of a conditional statement:
if (!strcmp(s,"volatile")) return QUALIFIER;
a zero result indicates false, so we have to negate it to get what we want. Here's a better way. Set up the definition:
#define STRCMP(a,R,b) (strcmp(a,b) R 0)
Now you can write a string in the natural style
if ( STRCMP(s, ==, "volatile"))
Using this definition, the code expresses what is happening in a more natural style. Try rewriting the cdecl program to use this style of string comparison, and see if you prefer it.
Programming Solution

Unscrambling a C Declaration (One More Time)
Here is the solution to "What is this declaration?" on page 78. In each step, the portion of the declaration we are dealing with is printed in bold type. Starting at step one, we will proceed through these steps:

Declaration Remaining Next Step to Apply

Result

start at the leftmost identifier

char *(*c [10])(int **p);

step 1

say "c is a…"

char *(* [10] )(int **p);

step 2

say "array[0..9] of…"

char *(* )(int **p);

step 5

say "pointer to…" go to step 4

char *() (int **p);

step 4

delete the parens, go to step 2, fall through step 2 to step 3

char * (int **p) ; step 3

say "function returning…"

char * ; char ;

step 5 step 6

say "pointer to…" say "char;"

Then put it all together to read:
"c is an array[0..9] of pointer to a function returning a pointer-to-char"
and we're done. Note: the fuctions pointed to in the array take a pointer to a pointer as their one and only parameter.

Chapter 4. The Shocking Truth: C Arrays and Pointers Are NOT the Same!
Should array indices start at 0 or 1? My compromise of 0.5 was rejected without, I thought, proper consideration.
—Stan Kelly-Bootle
arrays are NOT pointers…why doesn't my code work?…what's a declaration? what's a definition?…match your declarations to the definition…array and pointer differences…some light relief—fun with palindromes!
Arrays Are NOT Pointers!
One of the first things that novice C programmers often hear is that "arrays are the same as pointers." Unfortunately, this is a dangerous half-truth. The ANSI C Standard paragraph 6.5.4.2 recommends that you
Note the distinction between the declarations:

extern int *x; extern int y[];
The first declares x to be a pointer to int; the second declares y to be an array of int of
unspecified size (an incomplete type), the storage for which is defined elsewhere.
The standard doesn't go into the matter in any greater detail than that. Too many C books gloss over when arrays are, and are not, equivalent to pointers, relegating the explanation to a footnote when it should be a chapter heading. This book tries to restore the balance by fully explaining when arrays are equivalent to pointers, when they are not, and why. Not only that, but we also make sure that the key point is emphasized with a chapter heading, not a footnote.
Why Doesn't My Code Work?
If I had a dime for every time someone brought me a program like the following, together with the complaint that "it doesn't work," then I'd have, uh, let's see, about two-fifty.

file 1:

int mango[100];
file 2:

extern int *mango; ... /* some code that references mango[i] */
Here, file 1 defines mango as an array, but file 2 declares it as a pointer. But what is wrong with this?
After all, "everybody knows" arrays and pointers are pretty much the same in C. The problem is that "everybody" is wrong! It is like confusing integers and floats:
file 1:

int guava;
file 2:

extern float guava;
The int and float example above is an obvious and gross type mismatch; nobody would expect
this to work. So why do people think it's always OK to use pointers and arrays completely interchangeably? The answer is that array references can always be rewritten as pointer references, and there is a context in which pointer and array definitions are equivalent. Unfortunately, this context involves a very common use of arrays, so people naturally generalize and assume equivalence in all cases, including the blatantly wrong "defined as array/external declaration as pointer" above.

What's a Declaration? What's a Definition?
Before getting to the bottom of this problem, we need to refresh our memories about some essential C terminology. Recall that objects in C must have exactly one definition, and they may have multiple external declarations. By the way, no C++ mumbo-jumbo here—when we say "object" we mean a C "thing" known to the linker, like a function or data item.
A definition is the special kind of declaration that creates an object; a declaration indicates a name that allows you to refer to an object created here or elsewhere. Let's review the terminology:

definition occurs in only one specifies the type of an object; reserves storage for it; is used to create

place

new objects

example: int my_array[100];
declaration can occur multiple describes the type of an object; is used to refer to objects defined times

elsewhere (e.g., in another file)
example: extern int my_array[];
Handy Heuristic

Distinguishing a Definition from a Declaration You can tell these two apart by remembering:

A declaration is like a customs declaration:

it is not the thing itself, merely a description a definition is the special kind of

of some baggage that you say you have

declaration that fixes the storage

around somewhere.

for an object

The declaration of an external object tells the compiler the type and name of the object, and that memory allocation is done somewhere else. Since you aren't allocating memory for the array at this point, you don't need to provide information on how big it is in total. You do have to provide the size of all array dimensions except the leftmost one—this gives the compiler enough information to generate indexing code.
How Arrays and Pointers Are Accessed
In this section we show the difference between a reference using an array and a reference using a pointer. The first distinction we must note is between address y and contents of address y. This is actually quite a subtle point, because in most programming languages we use the same symbol to represent both, and the compiler figures out which is meant from the context. Take a simple assignment, as shown in Figure 4-1.
Figure 4-1. The Difference between an Address (l-value) and the Contents of the Address (r-value)

The symbol appearing on the left of an assignment is sometimes called an l-value (for "left-hand-side" or "locator" value), while a symbol on the right of an assignment is sometimes called an r-value (for "right-hand-side"). The compiler allocates an address (or l-value) to each variable. This address is known at compiletime, and is where the variable will be kept at runtime. In contrast, the value stored in a variable at runtime (its r-value) is not known until runtime. If the value stored in a variable is required, the compiler emits code to read the value from the given address and put it in a register.
The key point here is that the address of each symbol is known at compiletime. So if the compiler needs to do something with an address (add an offset to it, perhaps), it can do that directly and does not need to plant code to retrieve the address first. In contrast, the current value of a pointer must be retrieved at runtime before it can be dereferenced (made part of a further look-up). Diagram A shows an array reference.
Figure A. A Subscripted Array Reference
That's why you can equally write extern char a[]; as well as extern char a[100];.
Both declarations indicate that a is an array, namely a memory location where the characters in the array can be found. The compiler doesn't need to know how long the array is in total, as it merely generates address offsets from the start. To get a character from the array, you simply add the
subscript to the address that the symbol table shows a has, and get what's at that location.

In contrast, if you declare extern char *p, it tells the compiler that p is a pointer (a four-byte
object on many contemporary machines), and the object pointed to is a character. To get the char, you have to get whatever is at address p, then use that as an address and get whatever is there. Pointer accesses are more flexible, but at the cost of an extra fetch instruction, as shown in Diagram B.
Figure B. A Pointer Reference
What Happens When You "Define as Pointer/Reference as Array"
We now can see the problem that arises when an external array is defined as a pointer and referenced as an array. The indirect type of memory reference that is done for a pointer (see Diagram B) occurs when we really want a direct memory reference (as shown in Diagram A). This occurs because we told the compiler that we had a pointer, and is shown in Diagram C.
Figure C. A Subscripted Pointer Reference
Contrast the access shown in Diagram C on page 101
char * p = "abcdefgh"; ... p[3] with Diagram A on page 99 char a[] = "abcdefgh"; ... a[3] They both get you a character 'd' but they get there by very different look-ups. When you write extern char *p, then reference it as p[3], it's essentially a combination of
Diagrams A and B. You do an indirect reference as in diagram 2, then you step forward to the offset represented by the subscript as in diagram 1. More formally, the compiler emits code to:

1. Get the address that p represents, and retrieve the pointer there. 2. Add the offset that the subscript represents onto the pointer value. 3. Access the byte at the resulting address.
The compiler has been told that p is a pointer to char. (In contrast, an array definition tells the
compiler that p is a sequence of chars.) Making a reference to p[i] says "starting at where p points,
step forward over 'i' things, each of which is a char (i.e., 1 byte long)." For pointers to different types
(int or double, etc.) the scaling factor (the size of each thing stepped over) will be a different
number of bytes.
Since we declared p as a pointer, the look-up happens this way regardless of whether p was originally defined as a pointer (in which case the right thing is happening) or an array (in which case the wrong
thing is happening). Consider the case of an external declaration extern char *p; but a definition of char p[10];. When we retrieve the contents of p[i] using the extern, we get
characters, but we treat it as a pointer. Interpreting ASCII characters as an address is garbage, and if you're lucky the program will coredump at that point. If you're not lucky it will corrupt something in your address space, causing a mysterious failure at some later point in the program.
Match Your Declarations to the Definition
The problem of the external declaration of a pointer not matching the definition of an array is simple to fix—change the declaration so it does match the definition, like this:
file 1:
int mango[100];
file 2:
extern int mango[]; ... /* some code that references mango[i] */
The array definition of mango allocates space for 100 integers. In contrast, the pointer definition:
int *raisin;
requests a place that holds a pointer. The pointer is to be known by the name raisin, and can point to any int (or array of int) anywhere. The variable raisin itself will always be at the same address,
but its contents can change to point to many different ints at different times. Each of those different
ints can have different values. The array mango can't move around to different places. At different
times it can be filled with different values, but it always refers to the same 100 consecutive memory locations.

Other Differences Between Arrays and Pointers
Another way of looking at the differences between arrays and pointers is to compare some of their characteristics, as in Table 4-1.

Table 4-1. Differences Between Arrays and Pointers

Pointer

Array

Holds the address of data

Holds data

Data is accessed indirectly, so you first retrieve the

Data is accessed directly, so for a[i] you

contents of the pointer, load that as an address (call it "L"), simply retrieve the contents of the

then retrieve its contents.

location i units past a.

If the pointer has a subscript [i] you instead retrieve the
contents of the location 'i' units past "L" Commonly used for dynamic data structures
Commonly used with malloc(), free()
Typically points to anonymous data

Commonly used for holding a fixed number of elements of the same type of data
Implicitly allocated and deallocated
Is a named variable in its own right

Both arrays and pointers can be initialized with a literal string in their definition. Although these cases look the same, different things are happening.
A pointer definition does not allocate space for what's pointed at, only for the pointer, except when assigned a literal string. For example, the definition below also creates the string literal:

char *p = "breadfruit";
Note that this only works for a string literal. You can't expect to allocate space for, for example, a float literal:

float *pip = 3.141; /* Bzzt! won't compile */
A string literal created by a pointer initialization is defined as read-only in ANSI C; the program will exhibit undefined behavior if it tries to change the literal by writing through p. Some implementations put string literals in the text segment, where they will be protected with read-only permission.
An array can also be initialized with a string literal:

char a[] = "gooseberry";
In contrast to a pointer, an array initialized by a literal string is writable. The individual characters can later be changed. The following statement:

strncpy(a, "black", 5);
gives the string in the array the new value "blackberry".
Chapter 9 discusses when pointers and arrays are equivalent. It then discusses why the equivalency was made, and how it works. Chapter 10 describes some advanced array hocus-pocus based on pointers. If you make it to the end of that chapter, you will have forgotten more about arrays than many C programmers will ever know.
Pointers are one of the hardest parts of C to understand and apply correctly, second only to the syntax of declarations. However, they are also one of the most important parts of C. Professional C
programmers have to be proficient with the use of malloc() and pointers to anonymous memory.
Some Light Relief—Fun with Palindromes!
A palindrome is a word or phrase that reads the same backwards as forwards, for example, "do geese see God?" (Answer: "O, no!") Palindromes are a kind of entertaining parlor trick, and the best ones have phrases that make some kind of loose sense, such as Napoleon's last rueful words "Able was I, ere I saw Elba". Another classic palindrome refers to the heroic individual effort involved in building the Panama canal. The palindrome runs "A man, a plan, a canal—Panama!".
But of course, it took a lot more than just a man and a plan to produce the Panama canal—a fact noted by Jim Saxe, a computer science graduate student at Carnegie-Mellon University. In October 1983, Jim was idly doodling with the Panama palindrome, and extended it to:
A man, a plan, a cat, a canal—Panama?
Jim put this on the computer system where other graduate students would see it, and the race was on!
Steve Smith at Yale parodied the effort with:
A tool, a fool, a pool—loopaloofaloota!
Within a few weeks Guy Jacobson, had extended the panorama to:
A man, a plan, a cat, a ham, a yak, a yam, a hat, a canal—Panama!
Now people got seriously interested in palindromes about Panama! In fact Dan Hoey, who had recently graduated, wrote a C program to look for and construct the following beauty:
A man, a plan, a caret, a ban, a myriad, a sum, a lac, a liar, a hoop, a
pint, a catalpa, a gas, an oil, a bird, a yell, a vat, a caw, a pax, a wag,
a tax, a nay, a ram, a cap, a yam, a gay, a tsar, a wall, a car, a luger, a
ward, a bin, a woman, a vassal, a wolf, a tuna, a nit, a pall, a fret, a
watt, a bay, a daub, a tan, a cab, a datum, a gall, a hat, a fag, a zap, a

say, a jaw, a lay, a wet, a gallop, a tug, a trot, a trap, a tram, a torr, a caper, a top, a tonk, a toll, a ball, a fair, a sax, a minim, a tenor, a bass, a passer, a capital, a rut, an amen, a ted, a cabal, a tang, a sun, an ass, a maw, a sag, a jam, a dam, a sub, a salt, an axon, a sail, an ad, a wadi, a radian, a room, a rood, a rip, a tad, a pariah, a revel, a reel, a reed, a pool, a plug, a pin, a peek, a parabola, a dog, a pat, a cud, a nu, a fan, a pal, a rum, a nod, an eta, a lag, an eel, a batik, a mug, a mot, a nap, a maxim, a mood, a leek, a grub, a gob, a gel, a drab, a citadel, a total, a cedar, a tap, a gag, a rat, a manor, a bar, a gal, a cola, a pap, a yaw, a tab, a raj, a gab, a nag, a pagan, a bag, a jar, a bat, a way, a papa, a local, a gar, a baron, a mat, a rag, a gap, a tar, a decal, a tot, a led, a tic, a bard, a leg, a bog, a burg, a keel, a doom, a mix, a map, an atom, a gum, a kit, a baleen, a gala, a ten, a don, a mural, a pan, a faun, a ducat, a pagoda, a lob, a rap, a keep, a nip, a gulp, a loop, a deer, a leer, a lever, a hair, a pad, a tapir, a door, a moor, an aid, a raid, a wad, an alias, an ox, an atlas, a bus, a madam, a jag, a saw, a mass, an anus, a gnat, a lab, a cadet, an em, a natural, a tip, a caress, a pass, a baronet, a minimax, a sari, a fall, a ballot, a knot, a pot, a rep, a carrot, a mart, a part, a tort, a gut, a poll, a gateway, a law, a jay, a sap, a zag, a fat, a hall, a gamut, a dab, a can, a tabu, a day, a batt, a waterfall, a patina, a nut, a flow, a lass, a van, a mow, a nib, a draw, a regular, a call, a war, a stay, a gam, a yap, a cam, a ray, an ax, a tag, a wax, a paw, a cat, a valley, a drib, a lion, a saga, a plat, a catnip, a pooh, a rail, a calamus, a dairyman, a bater, a canal—Panama.

A "catalpa" (in case you're wondering) is a native American word for a type of tree. You can look up axon and calamus for yourself. Dan commented that a little work on the search algorithm could make it several times as long.
The search algorithm was ingenious—Dan programmed a finite state machine that evaluates a series of partial palindromes. In each case, the state consists of the unmatched part of the palindrome. Starting with the original palindrome, Dan noted that the "a ca" of "a canal" is right at the middle of the phrase, so we can add anything we like after "a plan" as long as its reverse forms a word or partword when put after that.
To insert additional words after "a plan," just start by doubling the "a ca" in the middle. This gives us "…, a plan, a ca… a canal,…" We could stop right there if "ca" was a word, but it's not. So find something that completes the fragment on the left, and add the same thing spelled backwards on the right, for example, "ret … ter."
In each step, the end part of the word we add is spelled backwards, and becomes the beginning part of the next word we look for. Table 4-2 shows the process:

State "-aca": State "ret-": State "-aba": State "n-": State "-adairyma": State "-a":

Table 4-2. Building a Palindrome
"A man, a plan, ... a canal, Panama" "... a plan, a caret, ... a canal, Panama" "... a plan, a caret, ... a bater, a canal, ..." "... a caret, a ban, ... a bater, a canal, ..." "... a caret, a ban, ... a dairyman, a bater, ..." "... a ban, a myriad, ... a dairyman, a bater, ..."

The accepting states of the finite state machine are those where the unmatched part is itself palindromic. In other words, at any point where the words just chosen are a palindrome in themselves, you can stop. In this case, the palindrome "… a nag, a pagan, …" is at the center, and putting in "-apa" terminated the algorithm.
Dan used a small word list that only contained nouns. If you don't do this you get a lot of "a how, a running, a would, an expect, an and..." which is nonsensical. An alternative would be a real on-line dictionary (not just word list) that indicates which words are nouns. That way, a really big palindrome could be generated. But as Dan says, "if I got a 10,000 word palindrome, I wonder if anyone would want it. I like this one, because it's small enough to pass around. And I've already done the work." You can't argue with that!

Programming Challenge

Write a Palindrome
Claim your 15 minutes of fame: write a C program to generate that 10,000-word palindrome. Really make yourself famous by posting it to rec.arts.startrek.misc on Usenet. They're fed up with discussing Captain Kirk's middle name, and they love to hear about new diversions.
Chapter 5. Thinking of Linking
As the Pall Mall Gazette described on March 11, 1889 "Mr Thomas Edison has been up on the two previous nights discovering 'a bug' in his phonograph."
—Thomas Edison discovers bugs, 1878
The pioneering Harvard Mark II computer system had a logbook which is now in the National Museum of American History at the Smithsonian. The logbook entry for September 9, 1947 has, taped onto the page, the remains of an insect that fluttered into a switch and got trapped. The label reads "Relay #70 Panel F (moth) in relay." Under this is written "First actual case of bug being found."
—Grace Hopper discovers bugs, 1947
As soon as we started programming, we found to our surprise that it wasn't as easy to get programs right as we had thought. Debugging had to be discovered. I can remember the exact instant when I realized that a large part of my life from then on was going to be spent in finding mistakes in my own programs.
—Maurice Wilkes discovers bugs, 1949
Program testing can be used to show the presence of bugs but never to show their absence.
—Edsger W. Dijkstra discovers bugs, 1972
linking, libraries, and loading…where the linker is in the phases of compilation…the benefits of dynamic linking…five special secrets of linking with libraries… watch out for interpositioning…don't use these names for your identifiers…generating linker report files…some light relief—look who's talking: challenging the Turing test
Libraries, Linking, and Loading
Let's start with a review of linker basics: The compiler creates an output file containing relocatable objects. These objects are the data and machine instructions corresponding to the source programs. This chapter uses the sophisticated form of linking found on all SVR4 systems as its example.
Where the Linker Is in the Phases of Compilation
Most compilers are not one giant program. They usually consist of up to half-a-dozen smaller programs, invoked by a control program called a "compiler driver." Some pieces that can be conveniently split out into individual programs are: the preprocessor, the syntactic and semantic checker, the code generator, the assembler, the optimizer, the linker, and, of course, a driver program

to invoke all these pieces and pass the right options to each (see Figure 5-1). An optimizer can be added after almost any of these phases. The current SPARCompilers do most optimizations on the intermediate representation between the front and back ends of the compiler.
Figure 5-1. A Compiler is Often Split into Smaller Programs

They are written in pieces because they are easier to design and maintain if each specialized part is a program in its own right. For instance, the rules controlling preprocessing are unique to that phase and

have little in common with the rest of C. The C preprocessor is often (but not always) a separate program. If the code generator (also known as the "back end") is written as a stand-alone program, it can probably be shared by other languages. The trade-off is that running several smaller programs will take longer than running one big program (because of the overhead of initiating a process and sending information between the phases). You can look at the individual phases of compilation by using the -# option. The -V option will provide version information.
You can pass options to each phase, by giving the compiler-driver a special -W option that says "pass this option to that phase." The "W" will be followed by a character indicating the phase, a comma, and then the option. The characters that represent each phase are shown in Figure 5-1.
So to pass any option through the compiler driver to the linker, you have to prefix it by "-Wl," to tell the compiler driver that this option is intended for the link editor, not the preprocessor, compiler, assembler, or another compilation phase. The command
cc -Wl,-m main.c > main.linker.map will give ld the "-m" option, telling it to produce a linker map. You should try this once or twice to see the kind of information that is produced.
An object file isn't directly executable; it needs to be fed into a linker first. The linker identifies the main routine as the initial entry point (place to start executing), binds symbolic references to memory addresses, unites all the object files, and joins them with the libraries to produce an executable.
There's a big difference between the linking facilities available on PC's and those on bigger systems.
PC's typically provide only a small number of elementary I/O services, known as the BIOS routines.
These exist in a fixed location in memory, and are not part of each executable. If a PC program or suite of programs requires more sophisticated services, they can be provided in a library, but the implementor must link the library into each executable. There's no provision in MS-DOS for "factoring out" a library common to several programs and installing it just once on the PC.
UNIX systems used to be the same. When you linked a program, a copy of each library routine that you used went into the executable. In recent years, a more modern and superior paradigm known as dynamic linking has been adopted. Dynamic linking allows a system to provide a big collection of libraries with many useful services, but the program will look for these at runtime rather than having the library binaries bound in as part of the executable. IBM's OS/2 operating system has dynamic linking, as does Microsoft's new flagship NT operating system. In recent years, Microsoft Windows® has introduced this ability for the windowing part of PC applications.
If a copy of the libraries is physically part of the executable, then we say the executable has been statically linked; if the executable merely contains filenames that enable the loader to find the program's library references at runtime, then we say it has been dynamically linked. The canonical names for the three phases of collecting modules together and preparing them for execution are linkediting, loading, and runtime linking. Statically linked modules are link edited and then loaded to run them. Dynamically linked modules are link-edited and then loaded and runtime-linked to run them. At
execution, before main() is called, the runtime loader brings the shared data objects into the process
address space. It doesn't resolve external function calls until the call is actually made, so there's no penalty to linking against a library that you may not call. The two linking methods are compared in Figure 5-2.
Figure 5-2. Static Linking versus Dynamic Linking

Even with static linking, the whole of libc. a is not brought into the executable, just the routines needed.
The Benefits of Dynamic Linking
Dynamic linking is the more modern approach, and has the advantage of much smaller executable size. Dynamic linking trades off more efficient use of the disk and a quicker link-edit phase for a small runtime penalty (since some of the linker's work is deferred until loadtime).
Handy Heuristic

